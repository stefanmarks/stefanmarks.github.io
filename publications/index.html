<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Stefan Marks </title> <meta name="author" content="Stefan Marks"> <meta name="description" content="List of my publications in reversed chronological order."> <meta name="keywords" content="stefanmarks, stefan-marks, portfolio, academia, photography, jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%8A&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://stefanmarks.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Stefan Marks </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">List of my publications in reversed chronological order.</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="lee2024mixedspace" class="col-sm-8"> <div class="title">Mixed interaction: evaluating user interactions for object manipulations in virtual space</div> <div class="author"> Y Lee, AM Connor, and S Marks </div> <div class="periodical"> <em>Journal on Multimodal User Interfaces</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/s12193-024-00431-2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://link.springer.com/article/10.1007/s12193-024-00431-2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>This paper presents an evaluation of a potential new interaction mode in virtual reality (VR) to determine whether it provides any positive impact in terms of how users interact with content. We evaluated the user experiences for 3D object manipulation across three modes of interaction. Interaction using controllers and gestures are used as baselines from which to gauge the potential value of the new mode of interaction, where a single controller and gestures are combined. This paper reports on a user study that captures quantitative and qualitative data related to a variety of object manipulation tasks in a Virtual Environment (VE). We investigated the impact of this new interaction mode with 40 participants across a number of interaction tasks, with the quantitative evaluation indicating that generally, the mixed mode of interaction resulted in task completion times consistently faster than gesture-based interaction and, in some cases, faster than with the use of controllers alone. A qualitative evaluation of the user experience indicated potential application areas for the new mode of interaction.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="randerson2024artistmoisture" class="col-sm-8"> <div class="title">Artist Talk on Ngā Raraunga o te Mākū: the data of moisture</div> <div class="author"> J Randerson, R Shearer, and S Marks </div> <div class="periodical"> Feb 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://www.instagram.com/khojstudios/p/C2zs9N8vDZc/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="bull2024ngmoisture" class="col-sm-8"> <div class="title">Ngā Rauranga o te Mākū: the data of moisture</div> <div class="author"> R Bull, S Marks , J Randerson, and R Shearer </div> <div class="periodical"> Jan 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://khojstudios.org/event/28-north-and-parallel-weathers/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2023mk22" class="col-sm-8"> <div class="title">Mākū, te hā o Haupapa: Moisture, the breath of Haupapa (2.2)</div> <div class="author"> S Marks , J Randerson, R Shearer, R Bull, and H Purdie </div> <div class="periodical"> Dec 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://pressroom.asia.siggraph.org/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>The SIGGRAPH Asia 2023 Art Gallery is a juried exhibition within the Experience Hall. The Art Gallery theme is "In Unruly Times." This theme encompasses a diverse range of works spanning art, science, and technology, including data visualization, 3D printing, XR, robotics, AI, sound, performance, NFTs, and interactive installations. "Unruly" here signifies a wild, experimental, and uncontrollable quality, reflecting turbulent moments in history, such as conflicts, climate crises, pandemics, inequality, surveillance, and financial and biosystem collapses. "Times" refers to various temporal aspects, including deep time, digital time, ancestral time, and finite resources. In these times, there is an increasing need for sustainable, inclusive, and agile practices that embrace diverse voices, experimental processes, and kindness. // A Note on Software and Physical Install Versions of each iteration of this collaborative work. In each of the following works the software was developed and the install setting was varied significantly: 1.0 Haupapa: the chilled breath of Rakamaomao (Online, Te Tuhi and World Weather Network websites, 2022) 2.0 Mākū: te hā o Haupapa (Te Tuhi, Iris Fisher Gallery, Auckland) 2.1 Ngā Raraunga o te Mākū: te ha o Haupapa. Blue Oyster, Dunedin. 2.2 Mākū, te hā o Haupapa: Moisture, the breath of Haupapa (Siggraph, Sydney – Proceedings &amp; Creative work) 2.3 Ngā Raraunga o te Mākū: the data of moisture (Khoj, New Delhi, 2024)</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2023mkhaupapa" class="col-sm-8"> <div class="title">Mākū, te hā o Haupapa: Moisture, the breath of Haupapa</div> <div class="author"> S Marks , J Randerson, R Shearer, R Bull, and H Purdie </div> <div class="periodical"> <em>In [Proceedings of] SA’23: SIGGRAPH Asia 2023 Art Gallery</em>, Dec 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1145/3610537.3622943" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://dx.doi.org/10.1145/3610537.3622943" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2023computerprogrammophobic" class="col-sm-8"> <div class="title">Computer graphics and extended reality courses for the programmophobic</div> <div class="author"> S Marks, and S Gil Parga </div> <div class="periodical"> <em>In [Proceedings of] SIGGRAPH Asia 2023 Educator’s Forum</em>, Dec 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1145/3610540.3627004" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://dx.doi.org/10.1145/3610540.3627004" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="bull2023nghaupapa" class="col-sm-8"> <div class="title">Ngā raraunga o te Mākū: te hā o Haupapa</div> <div class="author"> R Bull, S Marks , J Randerson, R Shearer, and H Purdie </div> <div class="periodical"> Sep 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://blueoyster.org.nz/exhibitions/nga-raraunga-o-te-maku-te-ha-o-haupapa/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="randerson2023artisthaupapa" class="col-sm-8"> <div class="title">Artist Talk: Ngā raraunga o te Mākū: te hā o Haupapa</div> <div class="author"> J Randerson, S Marks, R Shearer, and R Bull </div> <div class="periodical"> Sep 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://blueoyster.org.nz/events/nga-raraunga-o-te-maku-te-ha-o-haupapa-artist-talk/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="randerson2023mkhaupapa" class="col-sm-8"> <div class="title">Mākū: te hā o Haupapa</div> <div class="author"> J Randerson, S Marks, R Shearer, H Purdie, and R Bull </div> <div class="periodical"> Jun 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://tetuhi.art/huarere-weather-eye-weather-ear-list-of-works/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>MĀKŪ, te hā o Haupapa: Moisture, the breath of Haupapa Collaborating artists: Ron Bull (voice); Stefan Marks (programming); Janine Randerson (video); Rachel Shearer (sound); Heather Purdie, glaciologist and scientific advisor, University of Canterbury Live data stream courtesy of NIWA | Climate, Freshwater &amp; Ocean Science The cracking and melting Haupapa glacier and lake, Aotearoa’s fastest growing body of water, are present at Te Tuhi through a live cast of mākū, life-giving moisture. Tiny bubbles of ancient breath and atmosphere are pressed inside Haupapa’s glacial ice—including sea breezes, pollens, carbon dioxide and methane, as well as the ash of Australian fires. Ron Bull’s voice, recorded live on the lake, is woven through the sound and images to gift and acknowledge Kāi Tahu matauraka, words and names of the elemental ancestors. Glaciologist Heather Purdie’s research has centred on Haupapa lake and Haupapa glacier for many years. She has discovered that the glacier is melting from within crevasses in the glacier accumulation area that retain the sun’s heat; and that at the end of Haupapa, there are submerged ice ramps in the lake, which cause large icebergs to split off that accelerate glacier recession. Rachel and Janine gathered images and sounds from visits to Haupapa glacier in March and September in 2022 with Ron and Heather as guides. Spring is the most turbulent month when ice calves off, separating from the terminus of the glacier and the water is grey, while in March in late summer the water is clear and bright blue. Sound sequences occur in response to specific weathers and wind directions, constructed from atmospheric field and hydrophone recordings from 30 metres deep in the pro-glacial lake, digitally manipulated to create layered ambient textures. The artists relinquish the ordering and qualities of sound and video to the weather conditions of Aoraki, recorded by NIWA instruments in place near the Haupapa glacier. Stefan created a connection hub gathering the NIWA data stream, which is then used by the reactive installation to subtly alter the brightness, direction, and movement of the images and sounds according to the real-time weather conditions, and wind direction. Depending on the weather, the image changes and the sound and vocal sequence is endlessly variable. On days of high solar radiation, bright, clear ice and sun predominate and also move the images on screen accordingly, on cloudy days, the image darkens.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="gilparga2023pedagogicalreview" class="col-sm-8"> <div class="title">Pedagogical design in education using augmented reality: A systematic review</div> <div class="author"> S Gil Parga, U Singh, J Gutierrez, and S Marks </div> <div class="periodical"> <em>Interactive Learning Environments (NILE)</em>, Jun 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1080/10494820.2023.2195445" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="ayache2022humannessinteractions" class="col-sm-8"> <div class="title">Humanness is in the eye of the beholder: Role of predictability and theory of mind on anthropomorphism in human-computer interactions</div> <div class="author"> J Ayache, AM Connor, S Marks, A Sumich, and N Heym </div> <div class="periodical"> Dec 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="randerson2022haupapaatua" class="col-sm-8"> <div class="title">Haupapa: Approaching A Glacier. He mahi toi, he pūtaiao me ngā atua, Art, science and the atua</div> <div class="author"> J Randerson , J Randerson, R Shearer, M Sheehan, S Marks, H Purdie, R Bull, and HTT Himona </div> <div class="periodical"> Nov 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://leonardo.info/civicrm/event/info%3Fid%3D759%26reset%3D1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>https://tetuhi.art/event/haupapa-approaching-a-glacier/ He mahi toi, he pūtaiao me ngā atua, Art, science and the atua You are warmly invited to a kōrerorero, round table discussion with the collaborators of ‘Haupapa: The Chilled Breath of Rakamaomao’; an artwork that spans the fields of art, creative technologies, science, live data and Matauraka Māori. In mediating between these realms, in response to the melting Haupapa glacier in Aoraki National park, we sensorially approach a pressure zone where we face water scarcity in some parts of our isles, and vanishing glaciers, flooding, severe storms and coastal erosion that meets rising seas on the other. In the gathering of Ron Bull’s recitation of words and names of the atua of that locale, woven through sound and images collected through audio hydrophones and underwater camera, and triggered by a live data stream from NIWA (National Institute of Air and Water), we open up to more-than-human scales of aural and visual perception. We invite consideration of what ecological imaginaries might evolve through such voicings and data patterns of natural elements at a time of global crisis. In addition, we are interested in negotiating with care the realm of the sacred and the atua, and what is publicly shareable when bringing together parallel realms of knowledge.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="randerson2022haupaparakamaomao" class="col-sm-8"> <div class="title">Haupapa: The Chilled Breath of Rakamaomao</div> <div class="author"> J Randerson, S Marks, R Shearer, R Bull, and H Purdie </div> <div class="periodical"> Sep 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://tetuhi.art/world-weather-network/haupapa-project/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>See Also: https://worldweathernetwork.org/station/te-tuhi/ Haupapa: The Chilled Breath of Rakamaomao is an online artwork that assembles mountaineer-glaciologist Heather Purdie, sound artist/designer Rachel Shearer (Rongowhakāta Te Aitanga a Mahaki), moving image artist Janine Randerson, orator Ron Bull, of Kai Tahu, Kati Mamoe and Waitaha whakapapa, and programmer Stefan Marks. We create a creative "weather report" from Haupapa/Tasman glacier, Aotearoa’s largest body of wai, water, a glacier formed from a deep exhalation of Aoraki, the ancestor-maunga, as he readied to speak. We respond to the "hau" of Haupapa, translated fluidly as moisture, air, breath, wind, tears and vitality. Within Kai Tahu whakapapa, Rakamaomao is related to Aoraki and is one of the progenitors of wind and weather. Through audio-visual modes of gifting and listening, we approach Haupapa as ancestor, a shape-shifting collaborator. Tiny bubbles of ancient breath and atmosphere are pressed inside Haupapa’s glacial ice – including sea breezes, pollens, carbon dioxide and methane, as well as the ash of Australian fires. We collectively attune to the glacier through Kai Tahu cosmologies, instruments of science, audio hydrophones and underwater camera receivers to more-than-human scales of aural and visual perception.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="kruse2022evaluationsystem" class="col-sm-8"> <div class="title">Evaluation of a multi-agent ‘human-in-the-loop’ game design system</div> <div class="author"> J Kruse, AM Connor, and S Marks </div> <div class="periodical"> <em>ACM Transactions on Interactive Intelligent Systems</em>, Sep 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3531009" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p><jats:p>Designing games is a complicated and time-consuming process, where developing new levels for existing games can take weeks. Procedural content generation offers the potential to shorten this timeframe, however automated design tools are not adopted widely in the game industry. This paper presents an expert evaluation of a human-in-the-loop generative design approach for commercial game maps that incorporates multiple computational agents. The evaluation aims to gauge the extent to which such an approach could support and be accepted by human game designers, and to determine whether the computational agents improve the overall design. To evaluate the approach, eleven game designers utilized the approach to design game levels with the computational agents both active and inactive. Eye tracking, observational and think aloud data was collected to determine whether designers favored levels suggested by the computational agents. This data was triangulated with qualitative data from semi-structured interviews that were used to gather overall opinions of the approach. The eye tracking data indicates that the participating game level designers showed a clear preference for levels suggested by the computational agents, however expert designers in particular appeared to reject the idea that the computational agents are helpful. The perception of computational tools not being useful needs to be addressed if procedural content generation approaches are to fulfill their potential for the game industry.</jats:p></p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="ayache2021exploringcoordination" class="col-sm-8"> <div class="title">Exploring the “dark matter” of social interaction: Systematic review of a decade of research in spontaneous interpersonal coordination</div> <div class="author"> J Ayache, A Connor, S Marks, D Kuss, D Rhodes, A Sumich, and N Heym </div> <div class="periodical"> <em>Frontiers in Psychology</em>, Oct 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.3389/fpsyg.2021.718237" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2021.718237/full" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="ayache2021feelingspaces" class="col-sm-8"> <div class="title">Feeling closer despite the distance: How to cultivate togetherness within digital spaces</div> <div class="author"> J Ayache, N Heym, A Sumich, D Rhodes, AM Connor, and S Marks </div> <div class="periodical"> <em>In Handbook of research on remote work and worker well-being in the post-COVID-19 era</em>, Oct 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.4018/978-1-7998-6754-8.ch014" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://www.igi-global.com/chapter/feeling-closer-despite-the-distance/275127" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>In the framework of “togetherness” as a psychophysiological experience of social presence, the current chapter highlights the importance of work environments to socializing. The absence of such physical collective spaces impacts group-dynamics and team performance in online meetings, which also tend to prioritize task-solving discussions and limit non-verbal exchanges. Interpersonal coordination (or “social glue”), characterized by a spontaneous mutual attunement, both in speech and gestures, is classically observed during collective events where social-bonding and affiliation are promoted. This chapter will review the cognitive, behavioral, and physiological consequences of togetherness and integrate those in the context of recent technological advancements in computer-mediated interaction which have culminated in the advent of virtual and augmented reality. Given the potential of such methods to increase embodied interactions, they have been coined as “empathy machines” and could be seen as a technological solution to restore the experience of togetherness in the workplace.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="kruse2021andesign" class="col-sm-8"> <div class="title">An interactive multi-agent system for game design</div> <div class="author"> J Kruse, AM Connor, and S Marks </div> <div class="periodical"> <em>The Computer Games Journal</em>, Oct 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1007/s40869-020-00119-z" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="phan2020developmentequipment" class="col-sm-8"> <div class="title">Development of a virtual construction approach for steel structures considering structural and non- structural elements, and installation equipment</div> <div class="author"> T Phan, S Ramhormozian, C Clifton, G MacRae, R Dhakal, L-J Jia, and S Marks </div> <div class="periodical"> <em>In The 54th International Conference of the Architectural Science Association</em>, Oct 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://anzasca.net/paper/development-of-a-virtual-construction-approach-for-steel-structures-considering-structural-and-nonstructural-elements-and-installation-equipment/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="alex2020discreteartmaking" class="col-sm-8"> <div class="title">Discrete versus continuous colour pickers impact colour selection in virtual reality art-making</div> <div class="author"> M Alex, D Lottridge, J Lee, S Marks, and B Wünsche </div> <div class="periodical"> <em>In Proceedings of the 32nd Australian Conference on Human-Computer-Interaction (OzCHI 2020)</em>, Oct 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3441000.3441054" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>© 2020 ACM. Colour selection is an important task in digital art and 3D modelling applications. Most colour pickers are based on continuous colour spaces or a representative sampling of them, such as the Munsell colour palette. Continuous colour space-based pickers enable users to select from all colours by displaying full saturation hues with options to lower saturation and modify value. The two-step process of colour selection from continuous pickers requires understanding of 3D colour space, e.g., where to find "brown"or "sand". In this research we investigate how continuous versus discrete pickers affect colour selection in virtual art. We compared an HSV picker with a discrete picker in a study with 40 participants aged 16-60. We found that the colour picker impacted the kinds of colours used in artworks, with significant differences in colour distribution characteristics. We discuss implications of colour selection tools for virtual reality art-making.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="lee2020ancontrol" class="col-sm-8"> <div class="title">An evaluation of the effectiveness of virtual reality in air traffic control</div> <div class="author"> Y Lee, S Marks, and AM Connor </div> <div class="periodical"> <em>In Proceedings of the 4th International Conference on Virtual and Augmented Reality Simulations</em>, Oct 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1145/3385378.3385380" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://dl.acm.org/doi/abs/10.1145/3385378.3385380" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2020multideviceenvironments" class="col-sm-8"> <div class="title">Multi-device collaboration in virtual environments</div> <div class="author"> S Marks, and D White </div> <div class="periodical"> <em>In ICVARS 2020: Proceedings of the 2020 4th International Conference on Virtual and Augmented Reality Simulations</em>, Oct 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3385378.3385381" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://dl.acm.org/doi/abs/10.1145/3385378.3385381" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>We present a multi-device collaboration principle for virtual environments, using a combination of virtual and augmented reality (VR/AR) technology, used in the context of two educational applications, a virtual nasal cavity, and a visualisation of earthquake data. A head-mounted display (HMD) and a 3D-tracked tablet create two views of a shared virtual space. This allows two users to collaborate, utilising the strengths of each of the two technologies, e.g., intuitive spatial navigation and interaction in VR, and touch control of the visualisation parameters via the AR tablet. Touch gestures on the tablet are translated into a pointer ray in VR, so the users can easily indicate spatial features. The underlying networking infrastructure allows for an extension of this application to more than two users and across different rendering platforms.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="magdics2018extendingrendering" class="col-sm-8"> <div class="title">Extending a Virtual Reality Nasal Cavity Education Tool with Volume Rendering</div> <div class="author"> M Magdics, D White, and S Marks </div> <div class="periodical"> <em>In Proceedings of 2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)</em>, Dec 2018 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/TALE.2018.8615248" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://ieeexplore.ieee.org/abstract/document/8615248" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2018evaluationtool" class="col-sm-8"> <div class="title">Evaluation of a Virtual Reality Nasal Cavity Education Tool</div> <div class="author"> S Marks, D White, and M Magdics </div> <div class="periodical"> <em>In Proceedings of 2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)</em>, Dec 2018 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/TALE.2018.8615344" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://ieeexplore.ieee.org/document/8615344" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="nikolai2018activesector" class="col-sm-8"> <div class="title">Active learning and teaching through digital technology and live performance; ‘choreographic thinking’ as art practice in the tertiary sector</div> <div class="author"> J Nikolai, G Bennett, S Marks, and G Maynard </div> <div class="periodical"> <em>International Journal of Art and Design Education</em>, Sep 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/jade.12181" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>This article is an interdisciplinary reflective response to an intensive studio learning and teaching experience involving artists, academics and postgraduate students. The authors of this article teach, research and practise in coding, digital design, dance, and virtual and live performance. As lecturers and students we reflect upon and propose future approaches to art practice in tertiary education informed by live performance, performance capture and studio-based responses to digital and virtual platforms. We reflect on an innovative contribution to the field of research–teaching nexus as informed by digital and virtual data capture identifying the key element of immediacy in live performance and choreographic improvisation with systems. We reflect on practice-based inquiry via the Choreographic Coding Lab (CCL) model – a dialogical negotiation between capture technology and interdisciplinary artists in industry and academia. How can we encourage potential studio inquiry as an adapted model in tertiary learning and teaching? Our interdisciplinary voices, presented as authors’ reflections, provide suggestions for future studio-based, active learning contexts.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2018virtualreality" class="col-sm-8"> <div class="title">Virtual Reality</div> <div class="author"> S Marks </div> <div class="periodical"> <em>In The SAGE Encyclopedia of the Internet</em>, Sep 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.4135/9781473960367.n264" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://sk.sagepub.com/reference/the-sage-encyclopedia-of-the-internet-3v/i9318.xml" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>Popular media and recent consumer products give the impression that virtual reality (VR) is mostly about being tethered to a computer with a head-mounted display (HMD) covering the face, headphones over the ears, and some sort of controller in either hand for interaction. While this is indeed one valid incarnation of a VR system, it is not the only one. VR can be defined fairly broadly as synthetically generated sensory impressions (e.g., video, images, sound, touch) that are intended to immerse the users in an artificial, simulated, and interactive environment. This entry defines VR and discusses its history, hardware, and applications.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="sengupta2018fromimplementations" class="col-sm-8"> <div class="title">From von Neumann architecture and Atanasoffs ABC to neuro-morphic computation and Kasabov’s neuCube: Principles and implementations</div> <div class="author"> N Sengupta, JIE Ramos, E Tu, S Marks, N Scott, J Weclawski, AR Gollahalli, MG Doborjeh, ZG Doborjeh, K Kumarasinghe, V Breen, and A Abbott </div> <div class="periodical"> <em>In Studies in Computational Intelligence - Learning Systems: From Theory to Practice</em>, Sep 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-319-75181-8_1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://link.springer.com/chapter/10.1007/978-3-319-75181-8_1#citeas" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>© Springer International Publishing AG, part of Springer Nature 2018. During the 1940s John Atanasoff with the help of one of his students Clifford E. Berry, at Iowa State College, created the ABC (Atanasoff-Berry Computer) that was the first electronic digital computer. The ABC computer was not a general-purpose one, but still, it was the first to implement three of the most important ideas used in computers nowadays: binary data representation; using electronics instead of mechanical switches and wheels; using a von Neumann architecture, where the memory and the computations are separated. A new computational paradigm, named as Neuromorphic, utilises the above two principles, but instead of the von Neumann principle, it integrates the memory and the computation in a single module a spiking neural network structure. This chapter first reviews the principles of the earlier published work by the team on neuromorphic computational architecture NeuCube. NeuCube is not a general purpose machine but is still the first neuromorphic spatio/spectro-temporal data machine for learning, pattern recognition and understanding of spatio/spectro-temporal data. The chapter further presents the software/hardware implementation of the NeuCube as a development system for efficient applications on temporal or spatio/spectro-temporal across domain areas, including: brain data (EEG, fMRI), brain computer interfaces, robot control, multi-sensory data modelling, seismic stream data modelling and earthquake prediction, financial time series forecasting, climate data modelling and personalised, on-line risk of stroke prediction, and others. A limited version of the NeuCube software implementation is available from http://www.kedri.aut.ac.nz/neucube/.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2017drawingproject" class="col-sm-8"> <div class="title">Drawing on Hope: A Virtual Reality Project</div> <div class="author"> K Marks, and S Marks </div> <div class="periodical"> <em>In </em>, Dec 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://anzata.org/resources/Files/11.Events/Melb17/Melb17_Programme.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>This presentation introduces a Virtual Reality participatory art project, with a focus on social action (Levine &amp; Levine, 2011). ‘Drawing on Hope’ is a collaboration between Kathrin (Arts Therapy) and Stefan (Computer Science). The project is connecting countries through the universal language of art. As people interact with the virtual world by creating their own drawings of symbols and metaphors for hope, a collective artwork evolves, a forest of art that people can wander through, drawing on and with hope. The presentation further focuses on the role of hope within the therapeutic setting (Larsen, Edey, &amp; Lemay, 2007). A specific focus is on the dialectic between hope and despair (O’Hara, 2011) where the therapist often holds hope for the respective client until they feel able to invite it back into their own lives.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2017steptherapy" class="col-sm-8"> <div class="title">Step into my (virtual) world: An (auto)ethnographic exploration of virtual reality drawing applications for arts therapy</div> <div class="author"> K Marks, S Marks, and A Brown </div> <div class="periodical"> <em>Australian and New Zealand Journal of Arts Therapy (ANZJAT)</em>, Dec 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.jocat-online.org/s/13-ANZJAT-2017-KM-SM-AB-a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>This article explores the feasibility and potential of virtual reality (VR) in the context of arts therapy. Although technology advances at an ever-increasing rate, arts therapists have been slow and hesitant in taking up computers and software. Here the authors provide a brief overview of research to date into reasons for this apparent lack of adoption, and list the requirements of technology used in the context of therapy, followed by the introduction of VR applications for arts therapy. Employing art-based and practice-led research, they document their findings, which emerged in three phases: free exploration of the VR drawing application (open studio approach, transitional objects); use of the narrative therapy framework; and introduction to ANZATA symposium attendees in Christchurch in 2016. Based on these findings, the article highlights the benefits and limitations of using VR drawing applications in arts therapy.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2017gettinganatomy" class="col-sm-8"> <div class="title">Getting up your nose: A virtual reality education tool for nasal cavity anatomy</div> <div class="author"> S Marks, D White, and M Singh </div> <div class="periodical"> <em>In SIGGRAPH Asia 2017 Symposium on Education Proceedings</em>, Nov 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3134368.3139218" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://dl.acm.org/citation.cfm?id=3139218" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>This article explores the application of virtual reality (VR) to the area of anatomical education, specifically the shape of and the airflow through the human nasal cavity. We argue the benefits of VR technology in this specific domain, and describe the creation of the VR application which is intended to be used in future courses. Through two preliminary case studies, we describe our experiences, and discuss advantages and disadvantages of the use of VR in this area.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2017immersivenetworks" class="col-sm-8"> <div class="title">Immersive visualisation of 3-dimensional spiking neural networks</div> <div class="author"> S Marks </div> <div class="periodical"> <em>Evolving Systems</em>, Sep 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/s12530-016-9170-8" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://link.springer.com/article/10.1007/s12530-016-9170-8" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>Recent development in artificial neural networks has led to an increase in performance, but also in complexity and size. This poses a significant challenge for the exploration and analysis of the spatial structure and temporal behaviour of such networks. Several projects for the 3D visualisation of neural networks exist, but they focus largely on the exploration of the spatial structure alone, and are using standard 2D screens as output and mouse and keyboard as input devices. In this article, we present NeuVis, a framework for an intuitive and immersive 3D visualisation of spiking neural networks in virtual reality, allowing for a larger variety of input and output devices. We apply NeuVis to NeuCube, a 3-dimensional spiking neural network learning framework, significantly improving the user’s abilities to explore, analyse, and also debug the network. Finally, we discuss further venues of development and alternative render methods that are currently under development and will increase the visual accuracy and realism of the visualisation, as well as further extending its analysis and exploration capabilities.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2016stepworld" class="col-sm-8"> <div class="title">Step into my (virtual) world</div> <div class="author"> S Marks, and K Marks </div> <div class="periodical"> <em>In </em>, Dec 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Background: With an increasing number of clients growing up in the “information age”, interest in adopting new computer-based technologies is rising (Kapitan, 2007). Virtual reality (VR) based systems are one option, since recent technological advancements have made them more available to the consumer market. Methods: This study is primarily arts-based, focusing on the process and intuitive development of methods suited for VR-based tools. Participants were asked to "draw a problem", using narrative therapy in an art therapy framework. (Auto)ethnographic data was gathered through before and after reflections as well as during therapeutic conversations facilitated by the therapist. Results: To date, data from four participants has shown that the use of a VR painting tool in the context of art therapy opens new and exciting ways for clients to playfully explore their ‘problem’ in a non-verbal and experimental manner. Due to the intuitiveness of the tool and the mobility and unobtrusiveness of the custom VR hardware, participants were able to freely experiment with large 3D sculptures created within very short timeframes. A “teleport” function expands the available space and invites participants to vary distances to their ’problem’, achieving safety and perspective. Furthermore, the therapist can literally step into a client’s world (McLeod, 1999), deepening the therapeutic conversations. Conclusion: VR-based 3D painting applications are valuable additional tools that are attractive to an increasingly digital clientele. White latest technological developments have reduced the complexity and cost of such systems, they are, however, still too impractical or too expensive for widespread use</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2016stepworld2" class="col-sm-8"> <div class="title">Step into my (virtual) world</div> <div class="author"> S Marks, and K Marks </div> <div class="periodical"> <em>In Festival of Artful Transitions</em>, Nov 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Participants are invited to step into and explore 3D artworks created in therapeutic processes with some of the latest commercially available Virtual Reality (VR) technology. The workshop facilitators encourage discussion about the details of the process, possibilities, and challenges. Available technology permitting, there will also be an opportunity for participants to create, explore, and share their own virtual 3D artwork.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2016stepworld1" class="col-sm-8"> <div class="title">Step into my (virtual) world</div> <div class="author"> S Marks, and K Marks </div> <div class="periodical"> <em>In Artful Transitions - ANZATA 2016 Symposium Programme</em>, Nov 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.anzata.org/resources/Files/11.Events/PastEvents/Chch16_Programme-Nov.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>Collaborative research and exploration of art therapy within a virtual reality environment, using a tool similar to as well as the Google Tilt Brush. Three particular areas have been researched: 1. Use of an Open Studio approach 2. Possibility for creating/printing of transitional objects 3. Art and Narrative Therapy, using the prompt: “Draw your ‘problem’”, followed by therapeutic conversation and the therapist then literally stepping into the client’s world. These areas will be introduced as well as illustrated by (auto)ethnographic accounts through showing video footage, presenting 3D printed models, and inviting the audience to step into the virtual world.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="connor2016problemdisciplines" class="col-sm-8"> <div class="title">Problem solving at the edge of disciplines</div> <div class="author"> AM Connor, R Sosa, S Marks, and AG Jackson </div> <div class="periodical"> <em>In Handbook of Research on Creative Problem-Solving Skill Development in Higher Education</em>, Aug 2016 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.4018/978-1-5225-0643-0.ch010" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://www.igi-global.com/book/handbook-research-creative-problem-solving/147732" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="foottit2016acontroller" class="col-sm-8"> <div class="title">A wearable haptic game controller</div> <div class="author"> J Foottit, D Brown, S Marks, and AM Connor </div> <div class="periodical"> <em>International Journal of Game Theory and Technology</em>, Mar 2016 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.5121/ijgtt.2016.2101" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://airccse.org/journal/ijgtt/papers/1ijgtt02.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="connor2016creativeapplications" class="col-sm-8"> <div class="title">Creative Technologies for Multidisciplinary Applications</div> <div class="author"> AM Connor, and S Marks </div> <div class="periodical"> Mar 2016 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.4018/978-1-5225-0016-2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://www.igi-global.com/book/creative-technologies-multidisciplinary-applications/141944" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="shaw2016designexergaming" class="col-sm-8"> <div class="title">Design of a virtual trainer for exergaming</div> <div class="author"> LA Shaw, R Tourrel, B Wünsche, C Lutteroth, S Marks, and J Buckley </div> <div class="periodical"> <em>In ACM International Conference Proceeding Series</em>, Feb 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/2843043.2843384" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>Exergames are becoming increasingly popular as a way of motivating people to exercise. However, merely adding exercise elements to a game may not achieve the desired level of motivation and long term adherence. By designing an exergame which takes into account the user’s personality profile, the user’s level of motivation to play the game and thus exercise may be increased. In this paper, we present an exergame using a virtual trainer system which can be customized for the personality of the user. The trainer system supports two modes: a competitive mode for players who are motivated by pushing themselves to beat an opponent, and a cooperative mode for players who enjoy working with another player to perform well. We conduct a brief pilot study to evaluate our virtual trainers in which participants’ personalities are evaluated using the Sport Orientation Questionnaire. They then play three short sessions of the exergame: a control condition without a trainer system, and one for each of the two trainer system. Our initial results indicate that the training systems are highly motivating when matching the personality of the user, particularly for competitive individuals.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="connor2016exposingtechnologists" class="col-sm-8"> <div class="title">Exposing core competencies for future creative technologists</div> <div class="author"> AM Connor, R Sosa, S Karmokar, S Marks, M Buxton, AM Gribble, AG Jackson, and J Foottit </div> <div class="periodical"> <em>In Creative technologies for multidisciplinary applications</em>, Feb 2016 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.4018/978-1-5225-0016-2.ch015" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://www.igi-global.com/gateway/chapter/148576" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="kasabov2016evolvingapplications" class="col-sm-8"> <div class="title">Evolving spatio-temporal data machines based on the NeuCube neuromorphic framework: Design methodology and selected applications</div> <div class="author"> N Kasabov, NM Scott, E Tu, S Marks, N Sengupta, E Capecci, M Othman, MG Doborjeh, N Murli, R Hartono, JI Espinosa-Ramos, L Zhou, FB Alvi, G Wang, D Taylor, V Feigin, S Gulyaev, M Mahmoud, Z-G Hou, and J Yang </div> <div class="periodical"> <em>Neural Networks</em>, Feb 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.neunet.2015.09.011" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/S0893608015001860" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>The paper describes a new type of evolving connectionist systems (ECOS) called evolving spatio-temporal data machines based on neuromorphic, brain-like information processing principles (eSTDM). These are multi-modular computer systems designed to deal with large and fast spatio/spectro temporal data using spiking neural networks (SNN) as major processing modules. ECOS and eSTDM in particular can learn incrementally from data streams, can include ‘on the fly’ new input variables, new output class labels or regression outputs, can continuously adapt their structure and functionality, can be visualised and interpreted for new knowledge discovery and for a better understanding of the data and the processes that generated it. eSTDM can be used for early event prediction due to the ability of the SNN to spike early, before whole input vectors (they were trained on) are presented. A framework for building eSTDM called NeuCube along with a design methodology for building eSTDM using this is presented. The implementation of this framework in MATLAB, Java, and PyNN (Python) is presented. The latter facilitates the use of neuromorphic hardware platforms to run the eSTDM. Selected examples are given of eSTDM for pattern recognition and early event prediction on EEG data, fMRI data, multisensory seismic data, ecological data, climate data, audio-visual data. Future directions are discussed, including extension of the NeuCube framework for building neurogenetic eSTDM and also new applications of eSTDM.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="foottit2016developmentinterface" class="col-sm-8"> <div class="title">Development of a wearable haptic game interface</div> <div class="author"> J Foottit, D Brown, S Marks, and AM Connor </div> <div class="periodical"> <em>EAI Endorsed Transactions on Creative Technologies</em>, Feb 2016 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.4108/eai.25-4-2016.151165" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://eudl.eu/doi/10.4108/eai.25-4-2016.151165" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2015</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="connor2015creatingeducation" class="col-sm-8"> <div class="title">Creating creative technologists: Playing with(in) education</div> <div class="author"> AM Connor, S Marks, and C Walker </div> <div class="periodical"> <em>In Creativity in the Digital Age</em>, Apr 2015 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1007/978-1-4471-6681-8_3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://www.springer.com/gp/book/9781447166801" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2015immersivestructures" class="col-sm-8"> <div class="title">Immersive visualisation of 3-dimensional neural network structures</div> <div class="author"> S Marks, J Estevez, and N Scott </div> <div class="periodical"> <em>In 13th International Conference on Neuro-Computing and Evolving Intelligence (NCEI) 2015</em>, Feb 2015 </div> <div class="periodical"> </div> <div class="links"> <a href="http://www.kedri.aut.ac.nz/conferences/ncei15" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2015proceedings2015" class="col-sm-8"> <div class="title">Proceedings of the sixteenth Australasian User Interface Conference (AUIC 2015)</div> <div class="author"> S Marks, and Rachel Blagojevic </div> <div class="periodical"> Jan 2015 </div> <div class="periodical"> </div> <div class="links"> <a href="http://crpit.com/Vol162.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="shaw2015developmenttechnologies" class="col-sm-8"> <div class="title">Development and Evaluation of an Exercycle Game Using Immersive Technologies</div> <div class="author"> LA Shaw, B Wünsche, C Lutteroth, S Marks, J Buckley, and P Corballis </div> <div class="periodical"> <em>In Proceedings of the 8th Australasian Workshop on Health Informatics and Knowledge Management (HIKM 2015)</em>, Jan 2015 </div> <div class="periodical"> </div> <div class="links"> <a href="http://crpit.com/confpapers/CRPITV164Shaw.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="shaw2015challengesdesign" class="col-sm-8"> <div class="title">Challenges in virtual reality exergame design</div> <div class="author"> LA Shaw, B Wünsche, C Lutteroth, S Marks, and R Callies </div> <div class="periodical"> <em>In Conferences in Research and Practice in Information Technology (CRPIT)</em>, Jan 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://crpit.com/Vol162.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>Exercise video games have become increasingly popular due to their potential as tools to increase user motivation to exercise. In recent years we have seen an emergence of consumer level interface devices suitable for use in gaming. While past research has indicated that immersion is a factor in exergame effectiveness, there has been little research investigating the use of immersive interface technologies such as head mounted displays for use in exergames. In this paper we identify and discuss five major design challenges associated with the use of immersive technologies in exergaming: motion sickness caused by sensory disconnect when using a head mounted display, reliable bodily motion tracking controls, the health and safety concerns of exercising when using immersive technologies, the selection of an appropriate player perspective, and physical feedback latency. We demonstrate a prototype exergame utilising several affordable immersive gaming devices as a case study in overcoming these challenges. The results of a user study we conducted found that our prototype game was largely successful in overcoming these challenges, although further work would lead to improvement and we were able to identify further issues associated with the use of a head mounted display during exercise.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2014</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="connor2014anexperimentation" class="col-sm-8"> <div class="title">An unexpected journey: Experiences of learning through exploration and experimentation</div> <div class="author"> AM Connor, C Berthelsen, S Karmokar, S Marks, B Kenobi, and C Walker </div> <div class="periodical"> <em>In Action!-Doing Design Education</em>, Dec 2014 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.13140/2.1.2688.0805" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://www.designedasia.com/Full_Papers/2014/15_An%20Unexpected%20Journey.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="foottit2014ancontroller" class="col-sm-8"> <div class="title">An Intuitive Tangible Game Controller</div> <div class="author"> J Foottit, D Brown, S Marks, and AM Connor </div> <div class="periodical"> <em>In The 10th Australasian Conference on Interactive Entertainment (IE 2014)</em>, Dec 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/2677758.2677774" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://dl.acm.org/citation.cfm?id=2677758&amp;picked=prox&amp;cfid=603175386&amp;cftoken=76879377" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>This paper outlines the development of a sensory feedback device providing a low cost, versatile and intuitive interface for controlling digital environments, in this example a flight simulator. Gesture based input allows for a more immersive experience, so rather than making the user feel like they are controlling an aircraft the intuitive interface allows the user to become the aircraft that is controlled by the movements of the user’s hand. The movements are designed to feel intuitive and allow for a sense of immersion that would be difficult to achieve with an alternative interface. In this example the user’s hand can become the aircraft much the same way that a child would imagine it.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2014towardsdata" class="col-sm-8"> <div class="title">Towards the Holodeck: Fully immersive virtual reality visualisation of scientific and engineering data</div> <div class="author"> S Marks, JE Estevez, and AM Connor </div> <div class="periodical"> <em>In 29th International Conference on Image and Vision Computing New Zealand (IVCNZ) 2014</em>, Nov 2014 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1145/2683405.2683424" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://sci.waikato.ac.nz/about-us/engineering/image-and-vision-computing-new-zealand-2014-conference/programme" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="wnscheburkhard2014proceedings2014" class="col-sm-8"> <div class="title">Proceedings of the Fifteenth Australasian User Interface Conference (AUIC 2014)</div> <div class="author"> B Wünsche, and S Marks </div> <div class="periodical"> Jan 2014 </div> <div class="periodical"> </div> <div class="links"> <a href="http://crpit.com/Vol150.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2013</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2013experimentalvehicle" class="col-sm-8"> <div class="title">Experimental study of steer-by-wire ratios and response curves in a simulated high speed vehicle</div> <div class="author"> S Marks, and R Wellington </div> <div class="periodical"> <em>In Proceedings of the Fourteenth Australasian User Interface Conference (AUIC2013)</em>, Jan 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://crpit.com/confpapers/CRPITV139Marks.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>In this poster, we outline a research study of the steering system for a potential land speed record vehicle. We built a cockpit enclosure to simulate the interior space and employed a game engine to create a suitable virtual simulation and appropriate physical behaviour of the vehicle to give a realistic experience that has a suitable level of difficulty to represent the challenge of such a task. With this setup, we conducted experiments on different linear and nonlinear steering response curves to find the most suitable steering configuration. The results suggest that linear steering curves with a high steering ratio are better suited than non-linear curves, regardless of their gradient.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="wellingtonr2013anenvironment" class="col-sm-8"> <div class="title">An ethnographic study of a high cognitive load driving environment</div> <div class="author"> R Wellington, and S Marks </div> <div class="periodical"> <em>In Proceedings of the 14th Australasian User Interface Conference (AUIC 2013)</em>, Jan 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://crpit.com/Vol139.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>This poster outlines Ethnographic research into the design of an environment to study a land speed record vehicle, or more generally, a vehicle posing a high cognitive load for the user. The challenges of empirical research activity in the design of unique artifacts is discussed, where we may not have the artefact available in the real context to study, nor key informants that have direct relevant experience. We also describe findings from the preliminary design studies and the study into the design of the yoke for driving steer-by-wire.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2012</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="markss2012headtraining" class="col-sm-8"> <div class="title">Head Tracking Based Avatar Control for Virtual Environment Teamwork Training</div> <div class="author"> S Marks, JA Windsor, and B Wünsche </div> <div class="periodical"> <em>Journal of Virtual Reality and Broadcasting</em>, Dec 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://www.jvrb.org/9.2012/3560" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>Virtual environments (VE) are gaining in popularity and are increasingly used for teamwork training purposes,e.g., for medical teams. One shortcoming of modern VEs is that nonverbal communication channels, essential for teamwork, are not supported well. We address this issue by using an inexpensive webcam to track the user’s head. This tracking information is used to control the head movement of the user’s avatar, thereby conveying head gestures and adding a nonverbal communication channel. We conducted a user study investigating the influence of head tracking based avatar control on the perceived realism of the VE and on the performance of a surgical teamwork training scenario. Our results show that head tracking positively influences the perceived realism of the VE and the communication, but has no major influence on the training outcome.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2012usingtraining" class="col-sm-8"> <div class="title">Using Game Engine Technology for Virtual Environment Teamwork Training</div> <div class="author"> S Marks, JA Windsor, and B Wünsche </div> <div class="periodical"> <em>In WSCG ’2012 Conference Proceedings - Part 1</em>, Jul 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://wscg.zcu.cz/DL/wscg_DL.htm" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>The use of virtual environments (VE) for teaching and training is increasing rapidly. A particular popular medium for implementing such applications are game engines. However, just changing game content is usually insufficient for creating effective training and teaching scenarios. In this paper, we discuss how the design of a VE can be changed to adapt it to new use cases. We explain how new interaction principles can be added to a game engine by presenting technologies for integrating a webcam for head tracking. This enables head-coupled perspective as an intuitive view control and head gestures that are mapped onto the user’s avatar in the virtual environment. We also explain how the simulation can be connected to behavioural study software in order to simplify user study evaluation. Finally we list problems and solutions when utilising the free Source Engine Software Development Kit to design such a virtual environment. We evaluate our design, present a virtual surgery teamwork training scenario created with it, and summarize user study results demonstrating the usefulness of our extensions.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2012designequipment" class="col-sm-8"> <div class="title">Design and evaluation of a medical teamwork training simulator using consumer-level equipment</div> <div class="author"> S Marks, JA Windsor, and B Wünsche </div> <div class="periodical"> <em>In Medicine Meets Virtual Reality 19</em>, Jul 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3233/978-1-61499-022-2-273" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>Virtual environments (VE) are increasingly used for teamwork training purposes, e.g., for medical teams. One shortcoming is lack of support for nonverbal communication channels, essential for teamwork. We address this issue by using an inexpensive webcam to track the user’s head and using that data for controlling avatar head movement, thereby conveying head gestures and adding a nonverbal communication channel. In addition, navigation and orientation within the virtual environment is simplified. We present the design and evaluation of a simulation framework based on a game engine and consumer-level hardware and the results of two user studies showing, among other results, an improvement in the usability of the VE and in the perceived quality of realism and communication within the VE by using head tracking avatar and view control.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2011</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2011asoftware" class="col-sm-8"> <div class="title">A Virtual Environment for Medical Teamwork Training with Support for Non-Verbal Communication using Consumer-Level Hardware and Software</div> <div class="author"> S Marks </div> <div class="periodical"> <em></em> Sep 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://researchspace.auckland.ac.nz/handle/2292/7957" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>Simulation is an increasingly important component of the medical curriculum due to procedures becoming more complex and the use of real patients being constrained by ethical restrictions, costs, availability of patients, and logistics. A large number of simulators are available, mostly for training of technical skills, such as suturing or cutting, but increasingly also for non-technical skills, such as teamwork and decision making. The majority of those simulators are very expensive and unaffordable for smaller hospitals, healthcare providers, and education institutes, especially in third world countries. Furthermore the hardware and content are usually proprietary, making it difficult and expensive to add new functionalities. In this thesis, a virtual environment (VE) for medical teamwork training, based on consumer-level hardware and software, is presented and evaluated. Advanced graphics, physics and multi-user capabilities are provided by a game engine, and non-verbal communication, an important aspect of teamwork, is facilitated by using a standard webcam for tracking the movement of the user’s head and mirroring that movement onto the avatar. Different game engines are evaluated with regard to their suitability for medical simulations and guidelines and ideal parameters for stable head tracking using a web-cam are presented. Based on these results, a simulation framework is developed and evaluated for its suitability for medical teamwork training. A user study is presented, demonstrating that participants perceive non-verbal communication cues well and can intuitively control the view perspective with head movement. A multi-user study with a medical simulation scenario shows that the inclusion of view and avatar control by head tracking improves the perceived realism and naturalness of the simulation and the communication. The results demonstrate that medical simulators can be constructed using cheap consumer-level hardware and software. Game engines provide a suitable software foundation and allow users to design their own content. Peripheral devices, such as web-cams in combination with computer vision techniques, can be used to improve realism and immersion. Constraints centre predominantly on the simulation of complex technical skills and complex multi-user interactions.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2011virtualvehicle" class="col-sm-8"> <div class="title">Virtual environment for and physical simulation of a supersonic land speed record vehicle</div> <div class="author"> S Marks </div> <div class="periodical"> Jun 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://jetblacklsr.com/car/cockpit-design" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>JetBlack is a project striving to achieve a new land speed record. In order to develop the cockpit controls, I have developed a physical simulation of the vehicle to be used in conjunction with the chassis displayed in the HCI lab. This simulation provides a reasonably realistic and challenging simulation of driving the vehicle so that the vehicle controls have to be designed optimally to distract the driver as little as possible while at the same time providing as much information as necessary.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2011headtraining" class="col-sm-8"> <div class="title">Head tracking based avatar control for virtual environment teamwork training</div> <div class="author"> S Marks, JA Windsor, and B Wünsche </div> <div class="periodical"> <em>In GRAPP 2011 - Proceedings of the International Conference on Computer Graphics Theory and Applications</em>, May 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://www.grapp.visigrapp.org/Abstracts/2011/GRAPP_2011_Abstracts.htm" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>Virtual environments (VE) are gaining in popularity and are increasingly used for teamwork training purposes, e.g., for medical teams. One shortcoming of modern VEs is that nonverbal communication channels, essential for teamwork, are not supported well. We address this issue by using an inexpensive webcam to track the user’s head. This tracking information is used to control the head movement of the user’s avatar, thereby conveying head gestures and adding a nonverbal communication channel. We conducted a user study investigating the influence of head tracking based avatar control on the perceived realism of the VE and on the performance of a surgical teamwork training scenario. Our results show that head tracking positively influences the perceived realism of the VE and the communication, but has no major influence on the training outcome.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2010</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2010evaluationenvironments" class="col-sm-8"> <div class="title">Evaluation of the Effectiveness of Head Tracking for View and Avatar Control in Virtual Environments</div> <div class="author"> S Marks, JA Windsor, and B Wünsche </div> <div class="periodical"> <em>In 2010 25th International Conference Image and Vision Computing New Zealand, IVCNZ 2010 - Conference Proceedings</em>, Nov 2010 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/IVCNZ.2010.6148801" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>Virtual environments (VE) are gaining in popularity and are increasingly used for teamwork training purposes, e.g., for medical teams. We have identified two shortcomings of modern VEs: First, nonverbal communication channels are essential for teamwork but are not supported well. Second, view control in VEs is usually done manually, requiring the user to learn the controls before being able to effectively use them. We address those two shortcomings by using an inexpensive webcam to track the user’s head. The rotational movement is used to control the head movement of the user’s avatar, thereby conveying head gestures and adding a nonverbal communication channel. The translational movement is used to control the view of the VE in an intuitive way. Our paper presents the results of a user study designed to investigate how well users were able to use our system’s advantages.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2009</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2009optimisationtracking" class="col-sm-8"> <div class="title">Optimisation and comparison framework for monocular camera-based face tracking</div> <div class="author"> S Marks, JA Windsor, and B Wünsche </div> <div class="periodical"> <em>In 2009 24th International Conference Image and Vision Computing New Zealand, IVCNZ 2009 - Conference Proceedings</em>, Nov 2009 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/IVCNZ.2009.5378402" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5378402" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>Abstract—Tracking the position and orientation of the human face with respect to a camera has valuable applications in human computer interaction (HCI). Examples are navigating through a virtual environment, controlling objects using head gestures, and enabling avatars in a virtual environment to reflect the user’s behaviour. Tracking performance can be heavily influenced by environmental parameters. Developers and users of face tracking plugins without computer vision experience need guidelines how to optimise face tracking performance in real world set-ups and they need measures how environmental parameters influence the results. In this paper we develop a qualitative framework for determining ideal working conditions of face tracking algorithms. We apply our framework to a commercially available face tracking solution and present the results of this analysis.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2009thetraining" class="col-sm-8"> <div class="title">The Impact of Non-Verbal Communication in Virtual-Environment-Based Teamwork Training</div> <div class="author"> S Marks, JA Windsor, and B Wünsche </div> <div class="periodical"> <em>In SimTecT 2009 Health Simulation Conference</em>, Sep 2009 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://www.simulationaustralia.org.au/archive/simtect/2009health/papers.htm" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>Aims: To present a simple method to use a webcam to enhance non-verbal communication in virtual-environment-based teamwork training. Background: Over the last decade, healthcare profession training has been enriched by educational technology such as virtual-reality simulators for skills training and mannequins for team training. More recently, there has been the development of several metaverses that are now being used for virtual-environment-based teamwork simulations. This type of simulation lends itself to networking, allowing participants to participate from remote locations. The significant drawback of training in virtual worlds is that the avatars, in-world representatives of the participants, are capable of very limited non-verbal communication. Of note there is no facial expression, gaze control or head movement. Our thesis is that enhanced non-verbal communication will improve training outcomes. Methods: We have developed a model of the aspects of non-verbal communication that a simple webcam (Creative Live! Cam Video IM Pro) can capture. This model has been integrated into a program that monitors and evaluates the webcam input. The data is fed into a simulation based on Valve’s Source Engine that has been modified to mirror the information on the avatar. Results: Initial tests suggest a more realistic and effective communication between users in virtual world simulation. Feedback from medical and other professionals suggests that this approach has significant advantages and potential to enhance team training. Conclusions: Using additional input from a webcam to control the avatar, we have achieved enhanced non-verbal communication. Initial feedback is very positive. The next step is to conduct extended user studies.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2009enhancingcommunication3" class="col-sm-8"> <div class="title">Enhancing Virtual-Environment-Based Teamwork Training with Non-Verbal Communication</div> <div class="author"> S Marks, JA Windsor, and B Wünsche </div> <div class="periodical"> <em>In Proceedings of World Conference on Educational Multimedia, Hypermedia and Telecommunications 2009</em>, Jun 2009 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://editlib.org/p/32078/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>Virtual reality simulations for individual training of surgical skills are increasingly used in medical education and have been shown to improve patient outcome. Since recent research suggests that a large percentage of mistakes in clinical settings are due to problems with non-technical skills like communication, teamwork training simulators are developed and used to address this problem. Virtual-environment-based teamwork training simulators are very cost-efficient and allow for non-co-located settings, but have their limitations in communication among the participants. We present an inexpensive camera-based system for capturing aspects of non-verbal communication of participating users and projecting these onto the avatars in the simulation. This additional information has the potential of increasing the realism of the simulation and the effectiveness of team communication, resulting in a better training outcome – for all kinds of simulation that involves human communication.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2009enhancingcommunication2" class="col-sm-8"> <div class="title">Enhancing Virtual Environment-Based Surgical Teamwork Training with Non-Verbal Communication</div> <div class="author"> S Marks, JA Windsor, and B Wünsche </div> <div class="periodical"> <em>In New Zealand Computer Science Research Student Conference (NZCSRSC) 2009</em>, Apr 2009 </div> <div class="periodical"> </div> <div class="links"> <a href="http://nzcsrsc09.auckland.ac.nz/programme" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2009enhancingcommunication1" class="col-sm-8"> <div class="title">Enhancing Virtual Environment-Based Surgical Teamwork Training With Non-Verbal Communication</div> <div class="author"> S Marks, JA Windsor, and B Wünsche </div> <div class="periodical"> <em>In GRAPP 2009 - Proceedings of the 4th International Conference on Computer Graphics Theory and Applications</em>, Feb 2009 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://hdl.handle.net/10292/3454" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>Virtual reality simulations for training surgical skills are increasingly used in medical education and have been shown to improve patient outcome. While advances in hardware and simulation techniques have resulted in many commercial applications for training technical skills, most of these simulators are extremely expensive and do not consider non-technical skills like teamwork and communication. This is a major drawback since recent research suggests that a large percentage of mistakes in clinical settings are due to communication problems. In addition, training teamwork can also improve the efficiency of a surgical team and as such reduce costs and workload. We present an inexpensive camera-based system for capturing aspects of non-verbal communication of users participating in virtual environment-based teamwork simulations. This data can be used for the enhancement of virtual-environment-based simulations to increase the realism and effectiveness of team communication.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2008</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2008cameracommunication" class="col-sm-8"> <div class="title">Camera based face tracking for enhancing surgical teamwork training with non-verbal communication</div> <div class="author"> S Marks, JA Windsor, and B Wünsche </div> <div class="periodical"> <em>In 23rd International Conference Image and Vision Computing New Zealand, IVCNZ</em>, Nov 2008 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/IVCNZ.2008.4762122" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4762122" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>In recent years, the increased use of simulation for the training of surgical skills has improved the medical curriculum and the overall patient outcome. Advances in hardware and simulation techniques have resulted in many commercial applications for training technical skills. However, most of these simulators are extremely expensive and do not consider non-technical skills like teamwork and communication. This is a major drawback since recent research suggests that a a large percentage of mistakes in clinical settings are due to communication problems. In addition training teamwork can also improve the efficiency of a surgical team and as such reduce costs and workload. We present an inexpensive camera-based system for the acquisition of aspects of non-verbal communication of users participating in virtual environment-based teamwork simulations. This data can be used for the enhancement of virtual-environment-based simulations to increase the realism and effectiveness of team communication.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2008evaluationtraining" class="col-sm-8"> <div class="title">Evaluation of Game Engines for Simulated Clinical Training</div> <div class="author"> S Marks, JA Windsor, and B Wünsche </div> <div class="periodical"> <em>In </em>, Oct 2008 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://nzcsrsc08.canterbury.ac.nz/site/proceedings/NZCSRSC_2008_Proceedings.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>The increasing complexity and costs of clinical training and the constant development of new procedures has made virtual reality based training an essential tool in medical education. Unfortunately, commercial training tools are very expensive and have a small support base. Game engines offer unique advantages for the creation of highly interactive and collaborative environments. This paper examines the suitability of currently available game engines for developing applications for clinical education and training. We formally evaluate a list of available game engines for stability, availability, the possibility of custom content creation and the interaction of multiple users via a network. Based on these criteria, three of the highest ranked engines are used for further case studies. We found that in general it is possible to easily create scenarios with custom medical models that can be cooperatively viewed and interacted with, though limitations in physical simulation capabilities make some engines less suitable for fully interactive applications. We show that overall game engines represent a good foundation for low cost clinical training applications and we discuss technologies which can be used to further extend their physical simulation capabilities.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2007</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2007collaborativesimulators" class="col-sm-8"> <div class="title">Collaborative Soft Object Manipulation for Game Engine-Based Virtual Reality Surgery Simulators</div> <div class="author"> S Marks, JA Windsor, and B Wünsche </div> <div class="periodical"> <em>In 22nd International Conference Image and Vision Computing New Zealand, IVCNZ 2007</em>, Dec 2007 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://digital.liby.waikato.ac.nz/conferences/ivcnz07/papers/ivcnz07-paper38.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>In this paper we analyse and evaluate the capabilities of popular game engines to simulate and interact with soft objects. We discuss how these engines can be used for simulated surgical training applications, determine their shortcomings and make suggestions how game engines can be extended to make them more suitable for such applications.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2007evaluationtraining" class="col-sm-8"> <div class="title">Evaluation of game engines for simulated surgical training</div> <div class="author"> S Marks, JA Windsor, and B Wünsche </div> <div class="periodical"> <em>In Proceedings of the 5th International Conference on Computer Graphics and Interactive Techniques in Australia and Southeast Asia</em>, Dec 2007 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/1321261.1321311" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://portal.acm.org/citation.cfm?id=1321311" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>The increasing complexity and costs of surgical training and the constant development of new surgical procedures has made virtual surgical training an essential tool in medical education. Unfortunately, commercial tools are very expensive and have a small support base. Game engines offer unique advantages for the creation of highly interactive and collaborative environments. This paper examines the suitability of currently available game engines for developing applications for medical education and simulated surgical training. We formally evaluate a list of available game engines for stability, availability, the possibility of custom content creation and the interaction of multiple users via a network. Based on these criteria, three of the highest ranked engines are used for further case studies. We found that in general it is possible to easily create scenarios with custom medical models that can be cooperatively viewed and interacted with. Limitations in physical simulation capabilities make some engines unsuitable for fully interactive applications, but they can be used in combination with predefined animations. We show that overall game engines represent a good foundation for low cost virtual surgery applications and we discuss technologies which can be used to further extend their physical simulation capabilities.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2007dontthem" class="col-sm-8"> <div class="title">Don’t Shoot Them - Heal Them</div> <div class="author"> S Marks </div> <div class="periodical"> Oct 2007 </div> <div class="periodical"> This poster won the 1st prize at the University of Auckland 2007 Exposure poster competition </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://www.auckland.ac.nz/uoa/exposure-past-winners#s2c5" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>Virtual surgery training has become an essential tool in medical education. Unfortunately, commercial simulators are very expensive and mainly focus on individual training instead of teamwork. Game engines offer unique advantages for the inexpensive creation of interactive and collaborative environments. We show that it is possible to easily design multi-user scenarios with custom medical models. Our results will help to develop low cost surgical simulators that will improve health care outcomes for smaller hospitals or in regions which do not have access to advanced training tools.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="henriques2007anapplications" class="col-sm-8"> <div class="title">An investigation of meshless deformation for fast soft tissue simulation in virtual surgery applications</div> <div class="author"> A Henriques, B Wünsche, and S Marks </div> <div class="periodical"> <em>Computer-Assisted Radiology and Surgery</em>, Oct 2007 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1007/s11548-007-0091-7" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://www.springerlink.com/content/f927j24624473443/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2006</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2006evolvingstrategies2" class="col-sm-8"> <div class="title">Evolving autonomous locomotion of virtual characters in simulated physical environment via neural networks and evolutionary strategies</div> <div class="author"> S Marks, W Conen, and G Lux </div> <div class="periodical"> <em>In Proceedings of the ninth 3IA International Conference on Computer Graphics and Artificial Intelligence 3iA2006</em>, May 2006 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://3ia.teiath.gr/3ia_previous_conferences_cds/2006/Papers/ShortPaper01.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> </div> <div class="abstract hidden"> <p>In this paper we examine principles to automatise or to support the process of animation of an articulated character by allowing it to “learn” its movements autonomously. For this, it is necessary to model the physical properties of the character, connect virtual sensors and actuators to a neural network, and adjust the weights and thresholds of the network with evolutionary strategies. We conclude with a discussion and showcase of the results and present ways for further improvement.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="marks2006evolvingstrategies1" class="col-sm-8"> <div class="title">Evolving autonomous locomotion of virtual characters in a simulated physical environment via neural networks and evolutionary strategies</div> <div class="author"> S Marks </div> <div class="periodical"> <em></em> Jan 2006 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>The animation of virtual characters is a process that although supported by various software and hardware can be tedious and costly especially when the character to animate is very complicated and/or detailed. The method presented in this thesis tries to automatize or to support this process by letting the character ’learn’ its movements autonomously. This is established by first modelling physical properties (e.g. mass, inertia moments, joints, degrees of freedom) additionally to the optical ones to allow the interaction of the character with a simulated physical environment. In the second step the sensors (e.g. pressure, forces, angles, speed) and actors (e.g. motors, ’muscles’, suspension elements) that the character uses are defined. Third the sensors and actors are connected with the inputs and outputs of a neural network whose bias values and link weights are still uninitialized. These values are then modified by evolutionary strategies to find naturally looking movements of the character in its physical environment.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Stefan Marks. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"List of my publications in reversed chronological order.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"A collection of my projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-repositories",title:"repositories",description:"This page lists GiHub repositories that I have created or contributed to.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"projects-ar-bridge",title:"AR Bridge",description:"Augmented Reality bridge model for engineering education",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-ar-piha",title:"AR Piha",description:"Augmented Reality model for architectural prefvisualisation",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%73%74%65%66%61%6E.%6D%61%72%6B%73.%61%63@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0002-5997-3136","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=b0t3AiQAAAAJ","_blank")}},{id:"socials-publons",title:"Publons",section:"Socials",handler:()=>{window.open("https://publons.com/a/AAD-8614-2020/","_blank")}},{id:"socials-ieee-xplore",title:"IEEE Xplore",section:"Socials",handler:()=>{window.open("https://ieeexplore.ieee.org/author/37665380900/","_blank")}},{id:"socials-scopus",title:"Scopus",section:"Socials",handler:()=>{window.open("https://www.scopus.com/authid/detail.uri?authorId=27567815300","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/stefanmarks","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/stefanmarks","_blank")}},{id:"socials-work",title:"Work",section:"Socials",handler:()=>{window.open("https://academics.aut.ac.nz/stefan.marks","_blank")}},{id:"socials-facebook",title:"Facebook",section:"Socials",handler:()=>{window.open("https://facebook.com/stefan.marks.work","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>