@article{lee2024mixedspace,
author = {Lee, Y and Connor, AM and Marks, S},
journal = {Journal on Multimodal User Interfaces},
publisher = {Springer},
title = {Mixed interaction: evaluating user interactions for object manipulations in virtual space},
url = {https://link.springer.com/article/10.1007/s12193-024-00431-2},
year = {2024},
abstract = {This paper presents an evaluation of a potential new interaction mode in virtual reality (VR) to determine whether it provides any positive impact in terms of how users interact with content. We evaluated the user experiences for 3D object manipulation across three modes of interaction. Interaction using controllers and gestures are used as baselines from which to gauge the potential value of the new mode of interaction, where a single controller and gestures are combined. This paper reports on a user study that captures quantitative and qualitative data related to a variety of object manipulation tasks in a Virtual Environment (VE). We investigated the impact of this new interaction mode with 40 participants across a number of interaction tasks, with the quantitative evaluation indicating that generally, the mixed mode of interaction resulted in task completion times consistently faster than gesture-based interaction and, in some cases, faster than with the use of controllers alone. A qualitative evaluation of the user experience indicated potential application areas for the new mode of interaction.},
doi = {10.1007/s12193-024-00431-2},
issn = {1783-8738},
}
@misc{randerson2024artistmoisture,
author = {Randerson, J and Shearer, R and Marks, S},
month = {Feb},
organization = {New Delhi},
title = {Artist Talk on Ngā Raraunga o te Mākū: the data of moisture},
url = {https://www.instagram.com/khojstudios/p/C2zs9N8vDZc/},
year = {2024},
commissioningbody = {KHOJ STUDIOS},
conference = {28 Degrees North and Parallel Weathers},
day = {2},
}
@misc{bull2024ngmoisture,
author = {Bull, R and Marks, S and Randerson, J and Shearer, R},
month = {Jan},
organization = {Khōj},
publisher = {Khōj International Artists' Association},
title = {Ngā Rauranga o te Mākū: the data of moisture},
url = {https://khojstudios.org/event/28-north-and-parallel-weathers/},
year = {2024},
startyear = {2024},
startmonth = {Jan},
startday = {31},
finishyear = {2024},
finishmonth = {Mar},
finishday = {12},
conference = {28 North and Parallel Weathers},
numberofpieces = {1},
day = {31},
}
@misc{marks2023mk22,
author = {Marks, S and Randerson, J and Shearer, R and Bull, R and Purdie, H},
month = {Dec},
organization = {Siggraph Asia 2023, Sydney International Events Centre, Darling Harbour},
publisher = {Siggraph Asia 2023},
title = {Mākū, te hā o Haupapa: Moisture, the breath of Haupapa (2.2)},
url = {https://pressroom.asia.siggraph.org/},
year = {2023},
abstract = {The SIGGRAPH Asia 2023 Art Gallery is a juried exhibition within the Experience Hall. The Art Gallery theme is "In Unruly Times." This theme encompasses a diverse range of works spanning art, science, and technology, including data visualization, 3D printing, XR, robotics, AI, sound, performance, NFTs, and interactive installations. "Unruly" here signifies a wild, experimental, and uncontrollable quality, reflecting turbulent moments in history, such as conflicts, climate crises, pandemics, inequality, surveillance, and financial and biosystem collapses. "Times" refers to various temporal aspects, including deep time, digital time, ancestral time, and finite resources. In these times, there is an increasing need for sustainable, inclusive, and agile practices that embrace diverse voices, experimental processes, and kindness.

// A Note on Software and Physical Install Versions of each iteration of this collaborative work. In each of the following works the software was developed and the install setting was varied significantly:

1.0       Haupapa: the chilled breath of Rakamaomao (Online, Te Tuhi and World Weather Network websites, 2022)
2.0       Mākū: te hā o Haupapa (Te Tuhi, Iris Fisher Gallery, Auckland)
2.1       Ngā Raraunga o te Mākū: te ha o Haupapa. Blue Oyster, Dunedin.
2.2       Mākū, te hā o Haupapa: Moisture, the breath of Haupapa (Siggraph, Sydney – Proceedings \& Creative work)
2.3       Ngā Raraunga o te Mākū: the data of moisture (Khoj, New Delhi, 2024)},
startyear = {2023},
startmonth = {Dec},
startday = {12},
finishyear = {2023},
finishmonth = {Dec},
finishday = {15},
conference = {In Unruly Times, Siggraph Art Gallery},
numberofpieces = {1 Screen, custom software (version 2.2), stereo speakers},
day = {12},
}
@inproceedings{marks2023mkhaupapa,
author = {Marks, S and Randerson, J and Shearer, R and Bull, R and Purdie, H},
booktitle = {[Proceedings of] SA'23: SIGGRAPH Asia 2023 Art Gallery},
editor = {Spencer, S},
organization = {Sydney},
publisher = {ACM},
title = {Mākū, te hā o Haupapa: Moisture, the breath of Haupapa},
url = {http://dx.doi.org/10.1145/3610537.3622943},
year = {2023},
doi = {10.1145/3610537.3622943},
startyear = {2023},
startmonth = {Dec},
startday = {12},
finishyear = {2023},
finishmonth = {Dec},
finishday = {15},
isbn = {979-8-4007-0308-9},
conference = {SA'23: SIGGRAPH Asia 2023 Art Gallery},
}
@inproceedings{marks2023computerprogrammophobic,
author = {Marks, S and Gil Parga, S},
booktitle = {[Proceedings of] SIGGRAPH Asia 2023 Educator's Forum},
editor = {Kim, J and Aoki, M and Bennett, G},
organization = {Sydney},
publisher = {ACM},
title = {Computer graphics and extended reality courses for the programmophobic},
url = {http://dx.doi.org/10.1145/3610540.3627004},
year = {2023},
doi = {10.1145/3610540.3627004},
startyear = {2023},
startmonth = {Dec},
startday = {12},
finishyear = {2023},
finishmonth = {Dec},
finishday = {15},
isbn = {9798400703119},
conference = {SA '23: SIGGRAPH Asia 2023 Educator's Forum},
}
@misc{bull2023nghaupapa,
author = {Bull, R and Marks, S and Randerson, J and Shearer, R and Purdie, H},
month = {Sep},
organization = {Blue Oyster, 16 Dowling St, Ōtepoti},
publisher = {Blue Oyster},
title = {Ngā raraunga o te Mākū: te hā o Haupapa},
url = {https://blueoyster.org.nz/exhibitions/nga-raraunga-o-te-maku-te-ha-o-haupapa/},
year = {2023},
startyear = {2023},
startmonth = {Sep},
startday = {15},
finishyear = {2023},
finishmonth = {Oct},
finishday = {28},
conference = {Ngā raraunga o te Mākū: te hā o Haupapa},
numberofpieces = {1},
day = {15},
}
@misc{randerson2023artisthaupapa,
author = {Randerson, J and Marks, S and Shearer, R and Bull, R},
month = {Sep},
organization = {Otepoti Dunedin},
title = {Artist Talk: Ngā raraunga o te Mākū: te hā o Haupapa},
url = {https://blueoyster.org.nz/events/nga-raraunga-o-te-maku-te-ha-o-haupapa-artist-talk/},
year = {2023},
commissioningbody = {Blue Oyster},
conference = {Artist Talk: Ngā raraunga o te Mākū: te hā o Haupapa},
day = {15},
}
@misc{randerson2023mkhaupapa,
author = {Randerson, J and Marks, S and Shearer, R and Purdie, H and Bull, R},
month = {Jun},
organization = {Te Tuhi},
publisher = {Creative New Zealand; Te Tuhi; NIWA; Contemporary Art Foundation;},
title = {Mākū: te hā o Haupapa},
url = {https://tetuhi.art/huarere-weather-eye-weather-ear-list-of-works/},
year = {2023},
abstract = {MĀKŪ, te hā o Haupapa: Moisture, the breath of Haupapa
Collaborating artists: Ron Bull (voice); Stefan Marks (programming); Janine Randerson (video); Rachel Shearer (sound); Heather Purdie, glaciologist and scientific advisor, University of Canterbury

Live data stream courtesy of NIWA | Climate, Freshwater \& Ocean Science

The cracking and melting Haupapa glacier and lake, Aotearoa’s fastest growing body of water, are present at Te Tuhi through a live cast of mākū, life-giving moisture. Tiny bubbles of ancient breath and atmosphere are pressed inside Haupapa’s glacial ice—including sea breezes, pollens, carbon dioxide and methane, as well as the ash of Australian fires. Ron Bull’s voice, recorded live on the lake, is woven through the sound and images to gift and acknowledge Kāi Tahu matauraka, words and names of the elemental ancestors. Glaciologist Heather Purdie’s research has centred on Haupapa lake and Haupapa glacier for many years. She has discovered that the glacier is melting from within crevasses in the glacier accumulation area that retain the sun’s heat; and that at the end of Haupapa, there are submerged ice ramps in the lake, which cause large icebergs to split off that accelerate glacier recession.

Rachel and Janine gathered images and sounds from visits to Haupapa glacier in March and September in 2022 with Ron and Heather as guides. Spring is the most turbulent month when ice calves off, separating from the terminus of the glacier and the water is grey, while in March in late summer the water is clear and bright blue. Sound sequences occur in response to specific weathers and wind directions, constructed from atmospheric field and hydrophone recordings from 30 metres deep in the pro-glacial lake, digitally manipulated to create layered ambient textures.

The artists relinquish the ordering and qualities of sound and video to the weather conditions of Aoraki, recorded by NIWA instruments in place near the Haupapa glacier. Stefan created a connection hub gathering the NIWA data stream, which is then used by the reactive installation to subtly alter the brightness, direction, and movement of the images and sounds according to the real-time weather conditions, and wind direction. Depending on the weather, the image changes and the sound and vocal sequence is endlessly variable. On days of high solar radiation, bright, clear ice and sun predominate and also move the images on screen accordingly, on cloudy days, the image darkens.},
startyear = {2023},
startmonth = {Jun},
startday = {4},
finishyear = {2023},
finishmonth = {Jul},
finishday = {30},
conference = {Huarere: Weather Eye, Weather Ear},
numberofpieces = {Two data projectors, live weather data and custom-built software, four speakers},
day = {4},
}
@article{gilparga2023pedagogicalreview,
author = {Gil Parga, S and Singh, U and Gutierrez, J and Marks, S},
journal = {Interactive Learning Environments (NILE)},
number = {NILE 2195445},
publisher = {Taylor and Francis},
title = {Pedagogical design in education using augmented reality: A systematic review},
year = {2023},
doi = {10.1080/10494820.2023.2195445},
issn = {1049-4820},
eissn = {1744-5191},
}
@misc{ayache2022humannessinteractions,
author = {Ayache, J and Connor, AM and Marks, S and Sumich, A and Heym, N},
month = {Dec},
organization = {Christchurch},
title = {Humanness is in the eye of the beholder: Role of predictability and theory of mind  on anthropomorphism in human-computer interactions},
year = {2022},
startyear = {2022},
startmonth = {Dec},
startday = {5},
finishyear = {2022},
finishmonth = {Dec},
finishday = {8},
conference = {HAI 2022: The 10th International Conference on Human-Agent Interaction},
day = {5},
}
@misc{randerson2022haupapaatua,
author = {Randerson, J and Randerson, J and Shearer, R and Sheehan, M and Marks, S and Purdie, H and Bull, R and Himona, HTT},
month = {Nov},
organization = {Auckland, New Zealand, ZOOM},
title = {Haupapa: Approaching A Glacier. He mahi toi, he pūtaiao me ngā atua, Art, science and the atua},
url = {https://worldweathernetwork.org/event/tetuhi-event-2/},
url = {https://leonardo.info/civicrm/event/info\%3Fid\%3D759\%26reset\%3D1},
year = {2022},
abstract = {https://tetuhi.art/event/haupapa-approaching-a-glacier/
He mahi toi, he pūtaiao me ngā atua, Art, science and the atua

You are warmly invited to a kōrerorero, round table discussion with the collaborators of ‘Haupapa: The Chilled Breath of Rakamaomao’; an artwork that spans the fields of art, creative technologies, science, live data and Matauraka Māori. In mediating between these realms, in response to the melting Haupapa glacier in Aoraki National park, we sensorially approach a pressure zone where we face water scarcity in some parts of our isles, and vanishing glaciers, flooding, severe storms and coastal erosion that meets rising seas on the other. In the gathering of Ron Bull's recitation of words and names of the atua of that locale, woven through sound and images collected through audio hydrophones and underwater camera, and triggered by a live data stream from NIWA (National Institute of Air and Water), we open up to more-than-human scales of aural and visual perception. We invite consideration of what ecological imaginaries might evolve through such voicings and data patterns of natural elements at a time of global crisis. In addition, we are interested in negotiating with care the realm of the sacred and the atua, and what is publicly shareable when bringing together parallel realms of knowledge.},
commissioningbody = {Te Tuhi and LASER (Leonardo Art Science Evening Rendezvous)},
conference = {LASER Talk (Leonardo Art Science Evening Rendezvous)},
day = {11},
}
@misc{randerson2022haupaparakamaomao,
author = {Randerson, J and Marks, S and Shearer, R and Bull, R and Purdie, H},
month = {Sep},
organization = {Te Tuhi/World Weather Network (International Platform)},
publisher = {Te Tuhi, Hiraani Himona},
title = {Haupapa: The Chilled Breath of Rakamaomao},
url = {https://haupapa.space/},
url = {https://tetuhi.art/world-weather-network/haupapa-project/},
year = {2022},
abstract = {See Also: https://worldweathernetwork.org/station/te-tuhi/

Haupapa: The Chilled Breath of Rakamaomao is an online artwork that assembles mountaineer-glaciologist Heather Purdie, sound artist/designer Rachel Shearer (Rongowhakāta Te Aitanga a Mahaki), moving image artist Janine Randerson, orator Ron Bull, of Kai Tahu, Kati Mamoe and Waitaha whakapapa, and programmer Stefan Marks. We create a creative "weather report" from Haupapa/Tasman glacier, Aotearoa’s largest body of wai, water, a glacier formed from a deep exhalation of Aoraki, the ancestor-maunga, as he readied to speak. We respond to the "hau" of Haupapa, translated fluidly as moisture, air, breath, wind, tears and vitality. Within Kai Tahu whakapapa, Rakamaomao is related to Aoraki and is one of the progenitors of wind and weather. 

Through audio-visual modes of gifting and listening, we approach Haupapa as ancestor, a shape-shifting collaborator. Tiny bubbles of ancient breath and atmosphere are pressed inside Haupapa’s glacial ice – including sea breezes, pollens, carbon dioxide and methane, as well as the ash of Australian fires. We collectively attune to the glacier through Kai Tahu cosmologies, instruments of science, audio hydrophones and underwater camera receivers to more-than-human scales of aural and visual perception.},
startyear = {2022},
startmonth = {Sep},
startday = {23},
finishyear = {2022},
finishmonth = {Nov},
finishday = {30},
conference = {Huarere: Weather Eye, Weather Ear},
numberofpieces = {1},
day = {23},
}
@article{kruse2022evaluationsystem,
author = {Kruse, J and Connor, AM and Marks, S},
journal = {ACM Transactions on Interactive Intelligent Systems},
number = {3},
pages = {1--26},
publisher = {Association for Computing Machinery (ACM)},
title = {Evaluation of a multi-agent ‘human-in-the-loop’ game design system},
volume = {12},
year = {2022},
abstract = {<jats:p>Designing games is a complicated and time-consuming process, where developing new levels for existing games can take weeks. Procedural content generation offers the potential to shorten this timeframe, however automated design tools are not adopted widely in the game industry. This paper presents an expert evaluation of a human-in-the-loop generative design approach for commercial game maps that incorporates multiple computational agents. The evaluation aims to gauge the extent to which such an approach could support and be accepted by human game designers, and to determine whether the computational agents improve the overall design. To evaluate the approach, eleven game designers utilized the approach to design game levels with the computational agents both active and inactive. Eye tracking, observational and think aloud data was collected to determine whether designers favored levels suggested by the computational agents. This data was triangulated with qualitative data from semi-structured interviews that were used to gather overall opinions of the approach. The eye tracking data indicates that the participating game level designers showed a clear preference for levels suggested by the computational agents, however expert designers in particular appeared to reject the idea that the computational agents are helpful. The perception of computational tools not being useful needs to be addressed if procedural content generation approaches are to fulfill their potential for the game industry.</jats:p>},
doi = {10.1145/3531009},
issn = {2160-6455},
eissn = {2160-6463},
language = {en},
}
@article{ayache2021exploringcoordination,
author = {Ayache, J and Connor, A and Marks, S and Kuss, D and Rhodes, D and Sumich, A and Heym, N},
journal = {Frontiers in Psychology},
month = {Oct},
number = {718237},
publisher = {Frontiers Media},
title = {Exploring the “dark matter” of social interaction: Systematic review of a decade of research in spontaneous interpersonal coordination},
url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2021.718237/full},
volume = {12},
year = {2021},
doi = {10.3389/fpsyg.2021.718237},
issn = {1664-1078},
day = {11},
}
@incollection{ayache2021feelingspaces,
address = {Hershey, PA, USA},
author = {Ayache, J and Heym, N and Sumich, A and Rhodes, D and Connor, AM and Marks, S},
booktitle = {Handbook of research on remote work and worker well-being in the post-COVID-19 era},
editor = {Wheatley, D and Hardill, I and Buglass, S},
number = {14},
pages = {243--264},
publisher = {IGI Global},
title = {Feeling closer despite the distance: How to cultivate togetherness within digital spaces},
url = {https://www.igi-global.com/chapter/feeling-closer-despite-the-distance/275127},
year = {2021},
abstract = {In the framework of “togetherness” as a psychophysiological experience of social presence, the current chapter highlights the importance of work environments to socializing. The absence of such physical collective spaces impacts group-dynamics and team performance in online meetings, which also tend to prioritize task-solving discussions and limit non-verbal exchanges. Interpersonal coordination (or “social glue”), characterized by a spontaneous mutual attunement, both in speech and gestures, is classically observed during collective events where social-bonding and affiliation are promoted. This chapter will review the cognitive, behavioral, and physiological consequences of togetherness and integrate those in the context of recent technological advancements in computer-mediated interaction which have culminated in the advent of virtual and augmented reality. Given the potential of such methods to increase embodied interactions, they have been coined as “empathy machines” and could be seen as a technological solution to restore the experience of togetherness in the workplace.},
doi = {10.4018/978-1-7998-6754-8.ch014},
isbn = {9781799867548},
}
@inproceedings{phan2020developmentequipment,
author = {Phan, T and Ramhormozian, S and Clifton, C and MacRae, G and Dhakal, R and Jia, L-J and Marks, S},
booktitle = {The 54th International Conference of the Architectural Science Association},
editor = {Ghaffarian Hoseini, A and Ghaffarianhoseini, A and Naismith, N},
organization = {Auckland},
pages = {405--414},
title = {Development of a virtual construction approach for steel structures considering structural and non- structural elements, and installation equipment},
url = {https://anzasca.net/paper/development-of-a-virtual-construction-approach-for-steel-structures-considering-structural-and-nonstructural-elements-and-installation-equipment/},
year = {2020},
startyear = {2020},
startmonth = {Nov},
startday = {26},
finishyear = {2020},
finishmonth = {Nov},
finishday = {27},
isbn = {9780992383572},
conference = {The 54th International Conference of the Architectural Science Association},
}
@inproceedings{alex2020discreteartmaking,
author = {Alex, M and Lottridge, D and Lee, J and Marks, S and Wünsche, B},
booktitle = {Proceedings of the 32nd Australian Conference on Human-Computer-Interaction (OzCHI 2020)},
editor = {Ahmadpour, N and Leong, T and Ploderer, B},
organization = {Sydney},
pages = {158--169},
publisher = {Association for Computing Machinery},
series = {ACM International Conference Proceeding Series},
title = {Discrete versus continuous colour pickers impact colour selection in virtual reality art-making},
year = {2020},
abstract = {© 2020 ACM. Colour selection is an important task in digital art and 3D modelling applications. Most colour pickers are based on continuous colour spaces or a representative sampling of them, such as the Munsell colour palette. Continuous colour space-based pickers enable users to select from all colours by displaying full saturation hues with options to lower saturation and modify value. The two-step process of colour selection from continuous pickers requires understanding of 3D colour space, e.g., where to find "brown"or "sand". In this research we investigate how continuous versus discrete pickers affect colour selection in virtual art. We compared an HSV picker with a discrete picker in a study with 40 participants aged 16-60. We found that the colour picker impacted the kinds of colours used in artworks, with significant differences in colour distribution characteristics. We discuss implications of colour selection tools for virtual reality art-making.},
doi = {10.1145/3441000.3441054},
startyear = {2020},
startmonth = {Dec},
startday = {2},
finishyear = {2020},
finishmonth = {Dec},
finishday = {4},
isbn = {9781450389754},
conference = {OzCHI '20: 32nd Australian Conference on Human-Computer Interaction},
}
@article{kruse2021andesign,
author = {Kruse, J and Connor, AM and Marks, S},
journal = {The Computer Games Journal},
number = {1},
pages = {41--63},
publisher = {Springer Science and Business Media LLC},
title = {An interactive multi-agent system for game design},
volume = {10},
year = {2021},
doi = {10.1007/s40869-020-00119-z},
issn = {2052-773X},
language = {en},
}
@inproceedings{lee2020ancontrol,
author = {Lee, Y and Marks, S and Connor, AM},
booktitle = {Proceedings of the 4th International Conference on Virtual and Augmented Reality Simulations},
organization = {Sydney},
pages = {7--17},
title = {An evaluation of the effectiveness of virtual reality in air traffic control},
url = {https://dl.acm.org/doi/abs/10.1145/3385378.3385380},
year = {2020},
doi = {10.1145/3385378.3385380},
startyear = {2020},
startmonth = {Feb},
startday = {14},
finishyear = {2020},
finishmonth = {Feb},
finishday = {16},
isbn = {978-1-4503-7694-5},
conference = {IVCARS 2020: 4th International Conference on Virtual and Augmented Reality Simulations},
}
@inproceedings{marks2020multideviceenvironments,
author = {Marks, S and White, D},
booktitle = {ICVARS 2020: Proceedings of the 2020 4th International Conference on Virtual and Augmented Reality Simulations},
organization = {Sydney},
pages = {35--38},
title = {Multi-device collaboration in virtual environments},
url = {https://dl.acm.org/doi/abs/10.1145/3385378.3385381},
year = {2020},
abstract = {We present a multi-device collaboration principle for virtual environments, using a combination of virtual and augmented reality (VR/AR) technology, used in the context of two educational applications, a virtual nasal cavity, and a visualisation of earthquake data. A head-mounted display (HMD) and a 3D-tracked tablet create two views of a shared virtual space. This allows two users to collaborate, utilising the strengths of each of the two technologies, e.g., intuitive spatial navigation and interaction in VR, and touch control of the visualisation parameters via the AR tablet. Touch gestures on the tablet are translated into a pointer ray in VR, so the users can easily indicate spatial features. The underlying networking infrastructure allows for an extension of this application to more than two users and across different rendering platforms.},
doi = {10.1145/3385378.3385381},
startyear = {2020},
startmonth = {Feb},
startday = {14},
finishyear = {2020},
finishmonth = {Feb},
finishday = {16},
isbn = {978-1-4503-7694-5},
conference = {2020 4th International Conference on Virtual and Augmented Reality Simulations (ICVARS 2020)},
}
@inproceedings{magdics2018extendingrendering,
author = {Magdics, M and White, D and Marks, S},
booktitle = {Proceedings of 2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)},
month = {Dec},
organization = {Wollongong, New South Wales},
pages = {811--814},
publisher = {IEEE},
title = {Extending a Virtual Reality Nasal Cavity Education Tool with Volume Rendering},
url = {https://ieeexplore.ieee.org/abstract/document/8615248},
volume = {35},
year = {2018},
doi = {10.1109/TALE.2018.8615248},
startyear = {2018},
startmonth = {Dec},
startday = {4},
finishyear = {2018},
finishmonth = {Dec},
finishday = {7},
isbn = {978-1-5386-6522-0},
issn = {2374-0191},
eissn = {2470-6698},
conference = {IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE) 2018},
day = {6},
}
@inproceedings{marks2018evaluationtool,
author = {Marks, S and White, D and Magdics, M},
booktitle = {Proceedings of 2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)},
month = {Dec},
organization = {Wollongong, New South Wales},
pages = {193--198},
publisher = {IEEE},
title = {Evaluation of a Virtual Reality Nasal Cavity Education Tool},
url = {https://ieeexplore.ieee.org/document/8615344},
volume = {35},
year = {2018},
doi = {10.1109/TALE.2018.8615344},
startyear = {2018},
startmonth = {Dec},
startday = {4},
finishyear = {2018},
finishmonth = {Dec},
finishday = {7},
isbn = {978-1-5386-6522-0},
issn = {2374-0191},
eissn = {2470-6698},
conference = {IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE) 2018},
day = {5},
}
@article{nikolai2018activesector,
author = {Nikolai, J and Bennett, G and Marks, S and Maynard, G},
journal = {International Journal of Art and Design Education},
month = {Sep},
number = {JADE12181},
publisher = {Wiley},
title = {Active learning and teaching through digital technology and live performance; ‘choreographic thinking’ as art practice in the tertiary sector},
year = {2018},
abstract = {This article is an interdisciplinary reflective response to an intensive studio learning and teaching experience involving artists, academics and postgraduate students. The authors of this article teach, research and practise in coding, digital design, dance, and virtual and live performance. As lecturers and students we reflect upon and propose future approaches to art practice in tertiary education informed by live performance, performance capture and studio-based responses to digital and virtual platforms. We reflect on an innovative contribution to the field of research–teaching nexus as informed by digital and virtual data capture identifying the key element of immediacy in live performance and choreographic improvisation with systems. We reflect on practice-based inquiry via the Choreographic Coding Lab (CCL) model – a dialogical negotiation between capture technology and interdisciplinary artists in industry and academia. How can we encourage potential studio inquiry as an adapted model in tertiary learning and teaching? Our interdisciplinary voices, presented as authors’ reflections, provide suggestions for future studio-based, active learning contexts.},
doi = {10.1111/jade.12181},
issn = {1476-8062},
day = {23},
}
@incollection{marks2018virtualreality,
author = {Marks, S},
booktitle = {The SAGE Encyclopedia of the Internet},
editor = {Warf, B},
pages = {906--911},
publisher = {SAGE},
school = {Thousand Oaks},
title = {Virtual Reality},
url = {http://sk.sagepub.com/reference/the-sage-encyclopedia-of-the-internet-3v/i9318.xml},
volume = {3},
year = {2018},
abstract = {Popular media and recent consumer products give the impression that virtual reality (VR) is mostly about being tethered to a computer with a head-mounted display (HMD) covering the face, headphones over the ears, and some sort of controller in either hand for interaction.
While this is indeed one valid incarnation of a VR system, it is not the only one. VR can be defined fairly broadly as synthetically generated sensory impressions (e.g., video, images, sound, touch) that are intended to immerse the users in an artificial, simulated, and interactive environment. This entry defines VR and discusses its history, hardware, and applications.},
doi = {10.4135/9781473960367.n264},
isbn = {9781473960367},
}
@incollection{sengupta2018fromimplementations,
author = {Sengupta, N and Ramos, JIE and Tu, E and Marks, S and Scott, N and Weclawski, J and Gollahalli, AR and Doborjeh, MG and Doborjeh, ZG and Kumarasinghe, K and Breen, V and Abbott, A},
booktitle = {Studies in Computational Intelligence - Learning Systems: From Theory to Practice},
editor = {Sgurev, V and Piuri, V and Jotsov, V},
pages = {1--28},
publisher = {Springer, Cham},
title = {From von Neumann architecture and Atanasoffs ABC to neuro-morphic computation and Kasabov’s neuCube: Principles and implementations},
url = {https://link.springer.com/chapter/10.1007/978-3-319-75181-8_1#citeas},
year = {2018},
abstract = {© Springer International Publishing AG, part of Springer Nature 2018. During the 1940s John Atanasoff with the help of one of his students Clifford E. Berry, at Iowa State College, created the ABC (Atanasoff-Berry Computer) that was the first electronic digital computer. The ABC computer was not a general-purpose one, but still, it was the first to implement three of the most important ideas used in computers nowadays: binary data representation; using electronics instead of mechanical switches and wheels; using a von Neumann architecture, where the memory and the computations are separated. A new computational paradigm, named as Neuromorphic, utilises the above two principles, but instead of the von Neumann principle, it integrates the memory and the computation in a single module a spiking neural network structure. This chapter first reviews the principles of the earlier published work by the team on neuromorphic computational architecture NeuCube. NeuCube is not a general purpose machine but is still the first neuromorphic spatio/spectro-temporal data machine for learning, pattern recognition and understanding of spatio/spectro-temporal data. The chapter further presents the software/hardware implementation of the NeuCube as a development system for efficient applications on temporal or spatio/spectro-temporal across domain areas, including: brain data (EEG, fMRI), brain computer interfaces, robot control, multi-sensory data modelling, seismic stream data modelling and earthquake prediction, financial time series forecasting, climate data modelling and personalised, on-line risk of stroke prediction, and others. A limited version of the NeuCube software implementation is available from http://www.kedri.aut.ac.nz/neucube/.},
doi = {10.1007/978-3-319-75181-8_1},
issn = {1860-949X},
day = {1},
}
@inproceedings{marks2017drawingproject,
author = {Marks, K and Marks, S},
month = {Dec},
organization = {Melbourne},
title = {Drawing on Hope: A Virtual Reality Project},
url = {http://anzata.org/resources/Files/11.Events/Melb17/Melb17_Programme.pdf},
year = {2017},
abstract = {This presentation introduces a Virtual Reality participatory art project, with a focus on social action (Levine \& Levine, 2011). ‘Drawing on Hope’ is a collaboration between Kathrin (Arts Therapy) and Stefan (Computer Science). 
The project is connecting countries through the universal language of art. As people interact with the virtual world by creating their own drawings of symbols and metaphors for hope, a collective artwork evolves, a forest of art that people can wander through, drawing on and with hope. The presentation further focuses on the role of hope within the therapeutic setting (Larsen, Edey, \& Lemay, 2007). A specific focus is on the dialectic between hope and despair (O’Hara, 2011) where the therapist often holds hope for the respective client until they feel able to invite it back into their own lives.},
startyear = {2017},
startmonth = {Dec},
startday = {8},
finishyear = {2017},
finishmonth = {Dec},
finishday = {11},
conference = {ANZATA/ACATA Conference 2017},
day = {9},
}
@article{marks2017steptherapy,
author = {Marks, K and Marks, S and Brown, A},
editor = {Linnell, S and Bush, S and Camden-Pratt, C and Green, D and Šegedin, V},
journal = {Australian and New Zealand Journal of Arts Therapy (ANZJAT)},
month = {Dec},
number = {10},
pages = {99--111},
publisher = {Australian and New Zealand Arts Therapy Association},
title = {Step into my (virtual) world: An (auto)ethnographic exploration of virtual reality drawing applications for arts therapy},
url = {https://www.jocat-online.org/s/13-ANZJAT-2017-KM-SM-AB-a.pdf},
volume = {12},
year = {2017},
abstract = {This article explores the feasibility and potential of virtual reality (VR) in the context of arts therapy. 
Although technology advances at an ever-increasing rate, arts therapists have been slow and hesitant in taking up computers and software. Here the authors provide a brief overview of research to date into reasons for this apparent lack of adoption, and list the requirements of technology used in the context of therapy, followed by the introduction of VR applications for arts therapy. Employing art-based and practice-led research, they document their findings, which emerged in three phases: free exploration of the VR drawing application (open studio approach, transitional objects); use of the narrative therapy framework; and introduction to ANZATA symposium attendees in Christchurch in 2016. Based on these findings, the article highlights the benefits and limitations of using VR drawing applications in arts therapy.},
issn = {1833-9948},
issue = {1},
}
@inproceedings{marks2017gettinganatomy,
author = {Marks, S and White, D and Singh, M},
booktitle = {SIGGRAPH Asia 2017 Symposium on Education Proceedings},
month = {Nov},
organization = {Bangkok},
publisher = {ACM},
title = {Getting up your nose: A virtual reality education tool for nasal cavity anatomy},
url = {https://dl.acm.org/citation.cfm?id=3139218},
year = {2017},
abstract = {This article explores the application of virtual reality (VR) to the area of anatomical education, specifically the shape of and the airflow through the human nasal cavity. We argue the benefits of VR technology in this specific domain, and describe the creation of the VR application which is intended to be used in future courses.
Through two preliminary case studies, we describe our experiences, and discuss advantages and disadvantages of the use of VR in this area.},
doi = {10.1145/3134368.3139218},
startyear = {2017},
startmonth = {Nov},
startday = {27},
finishyear = {2017},
finishmonth = {Nov},
finishday = {30},
isbn = {978-1-4503-5409-7},
conference = {SIGGRAPH Asia 2017 Symposium on Education},
day = {27},
}
@article{marks2017immersivenetworks,
author = {Marks, S},
journal = {Evolving Systems},
month = {Sep},
pages = {193--201},
publisher = {Springer Berlin Heidelberg},
title = {Immersive visualisation of 3-dimensional spiking neural networks},
url = {http://link.springer.com/article/10.1007/s12530-016-9170-8},
volume = {8},
year = {2017},
abstract = {Recent development in artificial neural networks has led to an increase in performance, but also in complexity and size. This poses a significant challenge for the exploration and analysis of the spatial structure and temporal behaviour of such networks. Several projects for the 3D visualisation of neural networks exist, but they focus largely on the exploration of the spatial structure alone, and are using standard 2D screens as output and mouse and keyboard as input devices. In this article, we present NeuVis, a framework for an intuitive and immersive 3D visualisation of spiking neural networks in virtual reality, allowing for a larger variety of input and output devices. We apply NeuVis to NeuCube, a 3-dimensional spiking neural network learning framework, significantly improving the user’s abilities to explore, analyse, and also debug the network. Finally, we discuss further venues of development and alternative render methods that are currently under development and will increase the visual accuracy and realism of the visualisation, as well as further extending its analysis and exploration capabilities.},
doi = {10.1007/s12530-016-9170-8},
issn = {1868-6486},
issue = {3},
}
@inproceedings{marks2016stepworld,
author = {Marks, S and Marks, K},
month = {Dec},
organization = {Sydney},
title = {Step into my (virtual) world},
year = {2016},
abstract = {Background: With an increasing number of clients growing up in the “information age”, interest in adopting new computer-based technologies is rising (Kapitan, 2007). Virtual reality (VR) based systems are one option, since recent technological advancements have made them more available to the consumer market.
Methods: This study is primarily arts-based, focusing on the process and intuitive development of methods suited for VR-based tools. Participants were asked to "draw a problem", using narrative therapy in an art therapy framework. (Auto)ethnographic data was gathered through before and after reflections as well as during therapeutic conversations facilitated by the therapist.
Results: To date, data from four participants has shown that the use of a VR painting tool in the context of art therapy opens new and exciting ways for clients to playfully explore their ‘problem’ in a non-verbal and experimental manner. Due to the intuitiveness of the tool and the mobility and unobtrusiveness of the custom VR hardware, participants were able to freely experiment with large 3D sculptures created within very short timeframes. A “teleport” function expands the available space and invites participants to vary distances to their 'problem', achieving safety and perspective. Furthermore, the therapist can literally step into a client’s world (McLeod, 1999), deepening the therapeutic conversations.
Conclusion: VR-based 3D painting applications are valuable additional tools that are attractive to an increasingly digital clientele. White latest technological developments have reduced the complexity and cost of such systems, they are, however, still too impractical or too expensive for widespread use},
startyear = {2016},
startmonth = {Dec},
startday = {7},
finishyear = {2016},
finishmonth = {Dec},
finishday = {9},
conference = {Society for Mental Health Research (SMHR) Conference 2016},
day = {8},
}
@inproceedings{marks2016stepworld2,
author = {Marks, S and Marks, K},
booktitle = {Festival of Artful Transitions},
editor = {Segedin, J},
month = {Nov},
organization = {Christchurch},
title = {Step into my (virtual) world},
year = {2016},
abstract = {Participants are invited to step into and explore 3D artworks created in therapeutic processes with some of the latest commercially available Virtual Reality (VR) technology. The workshop facilitators encourage discussion about the details of the process, possibilities, and challenges. Available technology permitting, there will also be an opportunity for participants to create, explore, and share their own virtual 3D artwork.},
startyear = {2016},
startmonth = {Nov},
startday = {5},
finishyear = {2016},
finishmonth = {Nov},
finishday = {6},
conference = {ANZATA Symposium 2016},
day = {6},
}
@inproceedings{marks2016stepworld1,
author = {Marks, S and Marks, K},
booktitle = {Artful Transitions - ANZATA 2016 Symposium Programme},
editor = {Segedin, J},
month = {Nov},
organization = {Christchurch},
title = {Step into my (virtual) world},
url = {https://www.anzata.org/resources/Files/11.Events/PastEvents/Chch16_Programme-Nov.pdf},
year = {2016},
abstract = {Collaborative research and exploration of art therapy within a virtual reality environment, using a tool similar to as well as the Google Tilt Brush.
Three particular areas have been researched:
1. Use of an Open Studio approach
2. Possibility for creating/printing of transitional objects
3. Art and Narrative Therapy, using the prompt: “Draw your ‘problem’”, followed by therapeutic conversation and the therapist then literally stepping into the client’s world.
These areas will be introduced as well as illustrated by (auto)ethnographic accounts through showing video footage, presenting 3D printed models, and inviting the audience to step into the virtual world.},
startyear = {2016},
startmonth = {Nov},
startday = {5},
finishyear = {2016},
finishmonth = {Nov},
finishday = {6},
conference = {Australian and New Zealand Arts Therapy (ANZATA) Symposium 2016},
day = {5},
}
@incollection{connor2016problemdisciplines,
author = {Connor, AM and Sosa, R and Marks, S and Jackson, AG},
booktitle = {Handbook of Research on Creative Problem-Solving Skill Development in Higher Education},
editor = {Zhou, C},
month = {Aug},
publisher = {IGI Global},
school = {Hershey, PA},
title = {Problem solving at the edge of disciplines},
url = {http://www.igi-global.com/book/handbook-research-creative-problem-solving/147732},
year = {2016},
doi = {10.4018/978-1-5225-0643-0.ch010},
isbn = {1522506438},
isbn = {9781522506430},
day = {1},
}
@article{foottit2016acontroller,
author = {Foottit, J and Brown, D and Marks, S and Connor, AM},
journal = {International Journal of Game Theory and Technology},
month = {Mar},
pages = {1--19},
publisher = {AIRCC Publishing Corporation},
title = {A wearable haptic game controller},
url = {http://airccse.org/journal/ijgtt/papers/1ijgtt02.pdf},
volume = {2},
year = {2016},
doi = {10.5121/ijgtt.2016.2101},
issn = {2455-0892},
issue = {1},
day = {31},
}
@book{connor2016creativeapplications,
author = {Connor, AM and Marks, S},
month = {Mar},
publisher = {IGI Global},
school = {Hershey, PA},
series = {Advances in Media, Entertainment, and the Arts (AMEA)},
title = {Creative Technologies for Multidisciplinary Applications},
url = {http://www.igi-global.com/book/creative-technologies-multidisciplinary-applications/141944},
year = {2016},
doi = {10.4018/978-1-5225-0016-2},
isbn = {1522500162},
isbn = {9781522500162},
numberofpieces = {15},
}
@inproceedings{shaw2016designexergaming,
author = {Shaw, LA and Tourrel, R and Wünsche, B and Lutteroth, C and Marks, S and Buckley, J},
booktitle = {ACM International Conference Proceeding Series},
month = {Feb},
organization = {The Australian National University},
publisher = {Association for Computing Machinery},
title = {Design of a virtual trainer for exergaming},
year = {2016},
abstract = {Exergames are becoming increasingly popular as a way of motivating people to exercise. However, merely adding exercise elements to a game may not achieve the desired level of motivation and long term adherence. By designing an exergame which takes into account the user's personality profile, the user's level of motivation to play the game and thus exercise may be increased. In this paper, we present an exergame using a virtual trainer system which can be customized for the personality of the user. The trainer system supports two modes: a competitive mode for players who are motivated by pushing themselves to beat an opponent, and a cooperative mode for players who enjoy working with another player to perform well. We conduct a brief pilot study to evaluate our virtual trainers in which participants' personalities are evaluated using the Sport Orientation Questionnaire. They then play three short sessions of the exergame: a control condition without a trainer system, and one for each of the two trainer system. Our initial results indicate that the training systems are highly motivating when matching the personality of the user, particularly for competitive individuals.},
doi = {10.1145/2843043.2843384},
startyear = {2016},
startmonth = {Feb},
startday = {2},
finishyear = {2016},
finishmonth = {Feb},
finishday = {5},
isbn = {9781450340427},
keyword = {Exergame},
keyword = {Head-mounted display},
keyword = {Immersion},
keyword = {Motivation},
keyword = {Trainer system},
language = {eng},
conference = {ACE 2016: Eighteenth Australasian Computing Education Conference},
day = {1},
}
@incollection{connor2016exposingtechnologists,
author = {Connor, AM and Sosa, R and Karmokar, S and Marks, S and Buxton, M and Gribble, AM and Jackson, AG and Foottit, J},
booktitle = {Creative technologies for multidisciplinary applications},
editor = {Connor, AM and Marks, S},
number = {15},
pages = {377--397},
publisher = {IGI Global},
school = {Hershey, PA},
title = {Exposing core competencies for future creative technologists},
url = {https://www.igi-global.com/gateway/chapter/148576},
year = {2016},
doi = {10.4018/978-1-5225-0016-2.ch015},
isbn = {9781522500162},
}
@article{kasabov2016evolvingapplications,
author = {Kasabov, N and Scott, NM and Tu, E and Marks, S and Sengupta, N and Capecci, E and Othman, M and Doborjeh, MG and Murli, N and Hartono, R and Espinosa-Ramos, JI and Zhou, L and Alvi, FB and Wang, G and Taylor, D and Feigin, V and Gulyaev, S and Mahmoud, M and Hou, Z-G and Yang, J},
journal = {Neural Networks},
pages = {1--14},
publisher = {Elsevier},
title = {Evolving spatio-temporal data machines based on the NeuCube neuromorphic framework: Design methodology and selected applications},
url = {http://www.sciencedirect.com/science/article/pii/S0893608015001860},
volume = {78},
year = {2016},
abstract = {The paper describes a new type of evolving connectionist systems (ECOS) called evolving spatio-temporal data machines based on neuromorphic, brain-like information processing principles (eSTDM). These are multi-modular computer systems designed to deal with large and fast spatio/spectro temporal data using spiking neural networks (SNN) as major processing modules. ECOS and eSTDM in particular can learn incrementally from data streams, can include ‘on the fly’ new input variables, new output class labels or regression outputs, can continuously adapt their structure and functionality, can be visualised and interpreted for new knowledge discovery and for a better understanding of the data and the processes that generated it. eSTDM can be used for early event prediction due to the ability of the SNN to spike early, before whole input vectors (they were trained on) are presented. A framework for building eSTDM called NeuCube along with a design methodology for building eSTDM using this is presented. The implementation of this framework in MATLAB, Java, and PyNN (Python) is presented. The latter facilitates the use of neuromorphic hardware platforms to run the eSTDM. Selected examples are given of eSTDM for pattern recognition and early event prediction on EEG data, fMRI data, multisensory seismic data, ecological data, climate data, audio-visual data. Future directions are discussed, including extension of the NeuCube framework for building neurogenetic eSTDM and also new applications of eSTDM.},
doi = {10.1016/j.neunet.2015.09.011},
issn = {1879-2782},
eissn = {0893-6080},
}
@article{foottit2016developmentinterface,
author = {Foottit, J and Brown, D and Marks, S and Connor, AM},
journal = {EAI Endorsed Transactions on Creative Technologies},
number = {e5},
pages = {1--10},
publisher = {EAI},
title = {Development of a wearable haptic game interface},
url = {http://eudl.eu/doi/10.4108/eai.25-4-2016.151165},
volume = {16},
year = {2016},
doi = {10.4108/eai.25-4-2016.151165},
issn = {2409-9708},
issue = {6},
}

@incollection{connor2015creatingeducation,
author = {Connor, AM and Marks, S and Walker, C},
booktitle = {Creativity in the Digital Age},
editor = {Zagalo, N and Branco, P},
month = {Apr},
number = {3},
pages = {35--56},
publisher = {Springer},
title = {Creating creative technologists: Playing with(in) education},
url = {http://www.springer.com/gp/book/9781447166801},
year = {2015},
doi = {10.1007/978-1-4471-6681-8_3},
isbn = {978-1-4471-6680-1},
numberofpieces = {13},
day = {1},
}
@inproceedings{marks2015immersivestructures,
author = {Marks, S and Estevez, J and Scott, N},
booktitle = {13th International Conference on Neuro-Computing and Evolving Intelligence (NCEI) 2015},
month = {Feb},
organization = {Auckland},
title = {Immersive visualisation of 3-dimensional neural network structures},
url = {http://www.kedri.aut.ac.nz/conferences/ncei15},
year = {2015},
startyear = {2015},
startmonth = {Feb},
startday = {19},
finishyear = {2015},
finishmonth = {Feb},
finishday = {20},
conference = {13th International Conference on Neuro-Computing and Evolving Intelligence (NCEI) 2015},
day = {20},
}
@book{marks2015proceedings2015,
author = {Marks, S and Blagojevic, Rachel},
editor = {Marks, Stefan and Blagojevic, Rachel},
month = {Jan},
publisher = {Australian Computer Society Inc},
school = {Sydney},
series = {Conferences in Research and Practice in Information Technology},
title = {Proceedings of the sixteenth Australasian User Interface Conference (AUIC 2015)},
url = {http://crpit.com/Vol162.html},
volume = {162},
year = {2015},
day = {30},
}
@inproceedings{shaw2015developmenttechnologies,
author = {Shaw, LA and Wünsche, B and Lutteroth, C and Marks, S and Buckley, J and Corballis, P},
booktitle = {Proceedings of the 8th Australasian Workshop on Health Informatics and Knowledge Management (HIKM 2015)},
editor = {Maeder, A and Warren, J},
month = {Jan},
organization = {Sydney, Australia},
pages = {75--85},
publisher = {Australian Computer Society Inc},
title = {Development and Evaluation of an Exercycle Game Using Immersive Technologies},
url = {http://crpit.com/confpapers/CRPITV164Shaw.pdf},
volume = {164},
year = {2015},
startyear = {2015},
startmonth = {Jan},
startday = {27},
finishyear = {2015},
finishmonth = {Jan},
finishday = {30},
isbn = {978-1-921770-44-9},
issn = {1445-1336},
conference = {8th Australasian Workshop on Health Informatics and Knowledge Management (HIKM 2015)},
day = {30},
}
@inproceedings{shaw2015challengesdesign,
author = {Shaw, LA and Wünsche, B and Lutteroth, C and Marks, S and Callies, R},
booktitle = {Conferences in Research and Practice in Information Technology (CRPIT)},
editor = {Marks, Stefan and Blagojevic, Rachel},
month = {Jan},
organization = {Sydney, Australia},
publisher = {Australian Computer Society Inc.},
title = {Challenges in virtual reality exergame design},
url = {http://crpit.com/Vol162.html},
volume = {162},
year = {2015},
abstract = {Exercise video games have become increasingly popular due to their potential as tools to increase user motivation to exercise. In recent years we have seen an emergence of consumer level interface devices suitable for use in gaming. While past research has indicated
that immersion is a factor in exergame effectiveness, there has been little research investigating the use of immersive interface technologies such as head mounted displays for use in exergames.
In this paper we identify and discuss five major design challenges associated with the use of immersive technologies in exergaming: motion sickness caused by sensory disconnect when using a head mounted display, reliable bodily motion tracking controls, the health and safety concerns of exercising when using immersive technologies, the selection of an appropriate player perspective, and physical feedback latency.
We demonstrate a prototype exergame utilising several affordable immersive gaming devices as a case study in overcoming these challenges. The results of a user study we conducted found that our prototype game was largely successful in overcoming these challenges, although further work would lead to improvement and we were able to identify further issues associated with the use of a head mounted display during exercise.},
startyear = {2015},
startmonth = {Jan},
startday = {27},
finishyear = {2015},
finishmonth = {Jan},
finishday = {30},
isbn = {978-1-921770-44-9},
issn = {1445-1336},
conference = {AUIC 2014},
day = {30},
}
@inproceedings{connor2014anexperimentation,
author = {Connor, AM and Berthelsen, C and Karmokar, S and Marks, S and Kenobi, B and Walker, C},
booktitle = {Action!-Doing Design Education},
editor = {Jachna, TT and McLafferty, E and Tzvetanova, YS},
month = {Dec},
organization = {Hong Kong},
title = {An unexpected journey: Experiences of learning through exploration and experimentation},
url = {http://www.designedasia.com/Full_Papers/2014/15_An\%20Unexpected\%20Journey.pdf},
year = {2014},
doi = {10.13140/2.1.2688.0805},
startyear = {2014},
startmonth = {Dec},
startday = {2},
finishyear = {2014},
finishmonth = {Oct},
finishday = {3},
isbn = {978-988-16721-8-6},
conference = {DesignEd Asia Conference 2014},
day = {2},
}
@inproceedings{foottit2014ancontroller,
author = {Foottit, J and Brown, D and Marks, S and Connor, AM},
booktitle = {The 10th Australasian Conference on Interactive Entertainment (IE 2014)},
editor = {Nesbitt, K and Blackmore, K},
month = {Dec},
organization = {Newcastle, NSW, Australia},
title = {An Intuitive Tangible Game Controller},
url = {http://dl.acm.org/citation.cfm?id=2677758\&picked=prox\&cfid=603175386\&cftoken=76879377},
year = {2014},
abstract = {This paper outlines the development of a sensory feedback device providing a low cost, versatile and intuitive interface for controlling digital environments, in this example a flight simulator. Gesture based input allows for a more immersive experience, so rather than making the user feel like they are controlling an aircraft the intuitive interface allows the user to become the aircraft that is controlled by the movements of the user's hand. The movements are designed to feel intuitive and allow for a sense of immersion that would be difficult to achieve with an alternative interface. In this example the user's hand can become the aircraft much the same way that a child would imagine it.},
doi = {10.1145/2677758.2677774},
startyear = {2014},
startmonth = {Dec},
startday = {2},
finishyear = {2014},
finishmonth = {Dec},
finishday = {3},
conference = {The 10th Australasian Conference on Interactive Entertainment (IE 2014)},
day = {2},
}
@inproceedings{marks2014towardsdata,
author = {Marks, S and Estevez, JE and Connor, AM},
booktitle = {29th International Conference on Image and Vision Computing New Zealand (IVCNZ) 2014},
month = {Nov},
organization = {Hamilton, New Zealand},
pages = {42--47},
publisher = {ACM},
title = {Towards the Holodeck: Fully immersive virtual reality visualisation of scientific and engineering data},
url = {http://sci.waikato.ac.nz/about-us/engineering/image-and-vision-computing-new-zealand-2014-conference/programme},
year = {2014},
doi = {10.1145/2683405.2683424},
startyear = {2014},
startmonth = {Nov},
startday = {19},
finishyear = {2014},
finishmonth = {Nov},
finishday = {21},
isbn = {978-1-4503-3184-5},
conference = {29th International Conference on Image and Vision Computing New Zealand (IVCNZ) 2014},
day = {20},
}
@book{wnscheburkhard2014proceedings2014,
author = {Wünsche, B and Marks, S},
editor = {Wünsche, B and Marks, S},
month = {Jan},
publisher = {Australian Computer Society Inc},
school = {Sydney},
series = {Conferences in Research and Practice in Information Technology},
title = {Proceedings of the Fifteenth Australasian User Interface Conference (AUIC 2014)},
url = {http://crpit.com/Vol150.html},
volume = {150},
year = {2014},
isbn = {978-1-921770-33-3},
day = {23},
}
@inproceedings{marks2013experimentalvehicle,
author = {Marks, S and Wellington, R},
booktitle = {Proceedings of the Fourteenth Australasian User Interface Conference (AUIC2013)},
editor = {Smith, R and Wünsche, B},
organization = {Adelaide, Australia},
pages = {123--124},
title = {Experimental study of steer-by-wire ratios and response curves in a simulated high speed vehicle},
url = {http://crpit.com/confpapers/CRPITV139Marks.pdf},
volume = {139},
year = {2013},
abstract = {In this poster, we outline a research study of the steering system for a potential land speed record vehicle.
We built a cockpit enclosure to simulate the interior space and employed a game engine to create a suitable virtual simulation and appropriate physical behaviour of the vehicle to give a realistic experience that has a suitable level of difficulty to represent the challenge of such a task. With this setup, we conducted experiments on different linear and nonlinear steering response curves to  find the most suitable steering configuration.
The results suggest that linear steering curves with a high steering ratio are better suited than non-linear curves, regardless of their gradient.},
startyear = {2013},
startmonth = {Jan},
startday = {29},
finishyear = {2013},
finishmonth = {Feb},
finishday = {1},
isbn = {978-1-921770-24-1},
issn = {1445-1336},
keyword = {yoke},
keyword = {steering},
keyword = {high cognitive load},
conference = {The 14th Australasian User Interface Conference (AUIC 2013)},
}
@inproceedings{wellingtonr2013anenvironment,
author = {Wellington, R and Marks, S},
booktitle = {Proceedings of the 14th Australasian User Interface Conference (AUIC 2013)},
editor = {Smith, R and Wünsche, B},
organization = {Adelaide, Australia},
pages = {121--122},
publisher = {Australian Computer Society Inc},
title = {An ethnographic study of a high cognitive load driving environment},
url = {http://crpit.com/Vol139.html},
volume = {139},
year = {2013},
abstract = {This poster outlines Ethnographic research into the design of an environment to study a land speed record vehicle, or more generally, a vehicle posing a high cognitive load for the user. The challenges of empirical research activity in the design of unique artifacts is discussed, where we may not have the artefact available in the real context to study, nor key informants that have direct relevant experience. We also describe findings from the preliminary design studies and the study into the design of the yoke for driving steer-by-wire.},
startyear = {2013},
startmonth = {Jan},
startday = {29},
finishyear = {2013},
finishmonth = {Feb},
finishday = {1},
isbn = {978-1-921770-24-1},
issn = {1445-1336},
keyword = {yoke},
keyword = {steering},
keyword = {ethnography},
keyword = {cognitive load},
conference = {Fourteenth Australasian User Interface Conference},
}
@article{markss2012headtraining,
author = {Marks, S and Windsor, JA and Wünsche, B},
journal = {Journal of Virtual Reality and Broadcasting},
month = {Dec},
title = {Head Tracking Based Avatar Control for Virtual Environment Teamwork Training},
url = {http://www.jvrb.org/9.2012/3560},
volume = {9.2012},
year = {2012},
abstract = {Virtual environments (VE) are gaining in popularity and are increasingly used for teamwork training purposes,e.g., for medical teams. One shortcoming of modern VEs is that nonverbal communication channels, essential for teamwork, are not supported well. We address this issue by using an inexpensive webcam to track the user’s head. This tracking information is used to control the head movement of the user’s avatar, thereby conveying head gestures and adding a nonverbal communication channel. We conducted a user study investigating the influence of head tracking based avatar control on the perceived realism of the VE and on the performance of a surgical teamwork training scenario. Our results show that head tracking positively influences the perceived realism of the VE and the communication, but has no major influence on the training outcome.},
keyword = {virtual environment},
keyword = {teamwork training},
keyword = {head tracking},
keyword = {head-coupled perspective},
keyword = {non-verbal communication},
day = {31},
}
@inproceedings{marks2012usingtraining,
author = {Marks, S and Windsor, JA and Wünsche, B},
booktitle = {WSCG '2012 Conference Proceedings - Part 1},
editor = {Skala, Vaclav},
month = {Jul},
organization = {Plzen},
pages = {169--177},
publisher = {WSCG Digital Library},
title = {Using Game Engine Technology for Virtual Environment Teamwork Training},
url = {http://wscg.zcu.cz/DL/wscg_DL.htm},
year = {2012},
abstract = {The use of virtual environments (VE) for teaching and training is increasing rapidly. A particular popular medium for implementing such applications are game engines. However, just changing game content is usually insufficient for creating effective training and teaching scenarios. In this paper, we discuss how the design of a VE can be changed to adapt it to new use cases. We explain how new interaction principles can be added to a game engine by presenting technologies for integrating a webcam for head tracking. This enables head-coupled perspective as an intuitive view control and head gestures that are mapped onto the user’s avatar in the virtual environment. We also explain how the simulation can be connected to behavioural study software in order to simplify user study evaluation. Finally we list problems and solutions when utilising the free Source Engine Software Development Kit to design such a virtual environment. We evaluate our design, present a virtual surgery teamwork training scenario created with it, and summarize user study results demonstrating the usefulness of our extensions.},
startyear = {2012},
startmonth = {Jun},
startday = {25},
finishyear = {2012},
finishmonth = {Jun},
finishday = {28},
isbn = {978-80-86943-79-4},
keyword = {Serious Game},
keyword = {Source Engine},
keyword = {Medical Teamwork Training},
keyword = {Head Tracking},
keyword = {Non-Verbal Communication},
keyword = {Head-Coupled Perspective},
conference = {WSCG 2012},
day = {28},
}
@inproceedings{marks2012designequipment,
author = {Marks, S and Windsor, JA and Wünsche, B},
booktitle = {Medicine Meets Virtual Reality 19},
editor = {J.D. Westwood and Westwood, SW and Felländer-Tsai, L and Haluck, RS and Robb, RA and Senger, S and Vosburgh, KG},
organization = {Newport Beach, California},
pages = {273--279},
publisher = {IOS Press},
title = {Design and evaluation of a medical teamwork training simulator using consumer-level equipment},
year = {2012},
abstract = {Virtual environments (VE) are increasingly used for teamwork training purposes, e.g., for medical teams. One shortcoming is lack of support for nonverbal communication channels, essential for teamwork. We address this issue by using an inexpensive webcam to track the user’s head and using that data for controlling avatar head movement, thereby conveying head gestures and adding a nonverbal communication channel. In addition, navigation and orientation within the virtual environment is simplified. We present the design and evaluation of a simulation framework based on a game engine and consumer-level hardware and the results of two user studies showing, among other results, an improvement in the usability of the VE and in the perceived quality of realism and communication within the VE by using head tracking avatar and view control.},
doi = {10.3233/978-1-61499-022-2-273},
startyear = {2012},
startmonth = {Feb},
startday = {8},
finishyear = {2012},
finishmonth = {Feb},
finishday = {11},
isbn = {978-1-61499-021-5},
keyword = {medicine},
keyword = {training},
keyword = {teamwork},
keyword = {virtual environment},
conference = {Medicine Meets Virtual Reality (MMVR) 19},
}
@phdthesis{marks2011asoftware,
author = {Marks, S},
editor = {Wünsche, B and Windsor, JA},
month = {Sep},
organization = {Auckland, New Zealand},
title = {A Virtual Environment for Medical Teamwork Training with Support for Non-Verbal Communication using Consumer-Level Hardware and Software},
url = {http://www.cs.auckland.ac.nz/~stefan},
url = {https://researchspace.auckland.ac.nz/handle/2292/7957},
year = {2011},
abstract = {Simulation is an increasingly important component of the medical curriculum due to procedures becoming more complex and the use of real patients being constrained by ethical restrictions, costs, availability of patients, and logistics. A large number of simulators are available, mostly for training of technical skills, such as suturing or cutting, but increasingly also for non-technical skills, such as teamwork and decision making. The majority of those simulators are very expensive and unaffordable for smaller hospitals, healthcare providers, and education institutes, especially in third world countries. Furthermore the hardware and content are usually proprietary, making it difficult and expensive to add new functionalities.
In this thesis, a virtual environment (VE) for medical teamwork training, based on consumer-level hardware and software, is presented and evaluated. Advanced graphics, physics and multi-user capabilities are provided by a game engine, and non-verbal communication, an important aspect of teamwork, is facilitated by using a standard webcam for tracking the movement of the user’s head and mirroring that movement onto the avatar. Different game engines are evaluated with regard to their suitability for medical simulations and guidelines and ideal parameters for stable head tracking using a web-cam are presented.
Based on these results, a simulation framework is developed and evaluated for its suitability for medical teamwork training. A user study is presented, demonstrating that participants perceive non-verbal communication cues well and can intuitively control the view perspective with head movement. A multi-user study with a medical simulation scenario shows that the inclusion of view and avatar control by head tracking improves the perceived realism and naturalness of the simulation and the communication.
The results demonstrate that medical simulators can be constructed using cheap consumer-level hardware and software. Game engines provide a suitable software foundation and allow users to design their own content. Peripheral devices, such as web-cams in combination with computer vision techniques, can be used to improve realism and immersion. Constraints centre predominantly on the simulation of complex technical skills and complex multi-user interactions.},
confidential = {False},
conference = {The University of Auckland},
day = {15},
}
@misc{marks2011virtualvehicle,
author = {Marks, S},
month = {Jun},
organization = {Auckland, New Zealand},
title = {Virtual environment for and physical simulation of a supersonic land speed record vehicle},
url = {http://jetblacklsr.com/car/cockpit-design},
year = {2011},
abstract = {JetBlack is a project striving to achieve a new land speed record. In order to develop the cockpit controls, I have developed a physical simulation of the vehicle to be used in conjunction with the chassis displayed in the HCI lab. This simulation provides a reasonably realistic and challenging simulation of driving the vehicle so that the vehicle controls have to be designed optimally to distract the driver as little as possible while at the same time providing as much information as necessary.},
startyear = {2011},
startmonth = {Jun},
startday = {13},
numberofpieces = {1},
day = {13},
}
@inproceedings{marks2011headtraining,
author = {Marks, S and Windsor, JA and Wünsche, B},
booktitle = {GRAPP 2011 - Proceedings of the International Conference on Computer Graphics Theory and Applications},
month = {May},
organization = {Vilamoura, Algarve, Portugal},
pages = {257--269},
title = {Head tracking based avatar control for virtual environment teamwork training},
url = {http://www.grapp.visigrapp.org/Abstracts/2011/GRAPP_2011_Abstracts.htm},
year = {2011},
abstract = {Virtual environments (VE) are gaining in popularity and are increasingly used for teamwork training purposes, e.g., for medical teams. One shortcoming of modern VEs is that nonverbal communication channels, essential for teamwork, are not supported well. We address this issue by using an inexpensive webcam to track the user’s head. This tracking information is used to control the head movement of the user’s avatar, thereby conveying head gestures and adding a nonverbal communication channel. We conducted a user study investigating the influence of head tracking based avatar control on the perceived realism of the VE and on the performance of a surgical teamwork training scenario. Our results show that head tracking positively influences the perceived realism of the VE and the communication, but has no major influence on the training outcome.},
startyear = {2011},
startmonth = {May},
startday = {5},
finishyear = {2011},
finishmonth = {May},
finishday = {7},
isbn = {978-989842545-4},
keyword = {virtual environment},
keyword = {head tracking},
keyword = {nonverbal communication},
keyword = {teamwork training},
keyword = {surgery},
conference = {International Conference on Computer Graphics Theory and Applications},
day = {8},
}
@inproceedings{marks2010evaluationenvironments,
author = {Marks, S and Windsor, JA and Wünsche, B},
booktitle = {2010 25th International Conference Image and Vision Computing New Zealand, IVCNZ 2010 - Conference Proceedings},
month = {Nov},
organization = {Queenstown, New Zealand},
pages = {1--8},
publisher = {IEEE},
title = {Evaluation of the Effectiveness of Head Tracking for View and Avatar Control in Virtual Environments},
year = {2010},
abstract = {Virtual environments (VE) are gaining in popularity and are increasingly used for teamwork training purposes, e.g., for medical teams. We have identified two shortcomings of modern VEs: First, nonverbal communication channels are essential for teamwork but are not supported well. Second, view control in VEs is usually done manually, requiring the user to learn the controls before being able to effectively use them. We address those two shortcomings by using an inexpensive webcam to track the user's head. The rotational movement is used to control the head movement of the user's avatar, thereby conveying head gestures and adding a nonverbal communication channel. The translational movement is used to control the view of the VE in an intuitive way. Our paper presents the results of a user study designed to investigate how well users were able to use our system's advantages.},
doi = {10.1109/IVCNZ.2010.6148801},
startyear = {2010},
startmonth = {Nov},
startday = {8},
finishyear = {2010},
finishmonth = {Nov},
finishday = {9},
isbn = {978-1-4244-9629-7},
issn = {2151-2191},
keyword = {virtual environments},
keyword = {face tracking},
keyword = {nonverbal communication},
conference = {International Conference Image and Vision Computing New Zealand (IVCNZ) 2010},
day = {8},
}
@inproceedings{marks2009optimisationtracking,
author = {Marks, S and Windsor, JA and Wünsche, B},
booktitle = {2009 24th International Conference Image and Vision Computing New Zealand, IVCNZ 2009 - Conference Proceedings},
month = {Nov},
organization = {Wellington, New Zealand},
pages = {243--248},
publisher = {IEEE},
title = {Optimisation and comparison framework for monocular camera-based face tracking},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5378402},
year = {2009},
abstract = {Abstract—Tracking the position and orientation of the human face with respect to a camera has valuable applications in human computer interaction (HCI). Examples are navigating through a virtual environment, controlling objects using head gestures, and enabling avatars in a virtual environment to reflect the user’s behaviour.
Tracking performance can be heavily influenced by environmental parameters. Developers and users of face tracking plugins without computer vision experience need guidelines how to optimise face tracking performance in real world set-ups and they need measures how environmental parameters influence the results.
In this paper we develop a qualitative framework for determining ideal working conditions of face tracking algorithms. We apply our framework to a commercially available face tracking solution and present the results of this analysis.},
doi = {10.1109/IVCNZ.2009.5378402},
startyear = {2009},
startmonth = {Nov},
startday = {23},
finishyear = {2009},
finishmonth = {Nov},
finishday = {25},
issn = {2151-2205},
keyword = {face tracking},
keyword = {camera},
keyword = {optimisation},
conference = {24th International Conference Image and Vision Computing New Zealand (IVCNZ) 2009},
day = {25},
}
@inproceedings{marks2009thetraining,
author = {Marks, S and Windsor, JA and Wünsche, B},
booktitle = {SimTecT 2009 Health Simulation Conference},
month = {Sep},
organization = {Melbourne, Australia},
title = {The Impact of Non-Verbal Communication in Virtual-Environment-Based Teamwork Training},
url = {http://www.simulationaustralia.org.au/archive/simtect/2009health/papers.htm},
year = {2009},
abstract = {Aims: To present a simple method to use a webcam to enhance non-verbal communication in virtual-environment-based teamwork training.
Background: Over the last decade, healthcare profession training has been enriched by educational technology such as virtual-reality simulators for skills training and mannequins for team training. More recently, there has been the development of several metaverses that are now being used for virtual-environment-based teamwork simulations. This type of simulation lends itself to networking, allowing participants to participate from remote locations.
The significant drawback of training in virtual worlds is that the avatars, in-world representatives of the participants, are capable of very limited non-verbal communication. Of note there is no facial expression, gaze control or head movement. Our thesis is that enhanced non-verbal communication will improve training outcomes.
Methods: We have developed a model of the aspects of non-verbal communication that a simple webcam (Creative Live! Cam Video IM Pro) can capture. This model has been integrated into a program that monitors and evaluates the webcam input. The data is fed into a simulation based on Valve’s Source Engine that has been modified to mirror the information on the avatar.
Results: Initial tests suggest a more realistic and effective communication between users in virtual world simulation. Feedback from medical and other professionals suggests that this approach has significant advantages and potential to enhance team training.
Conclusions: Using additional input from a webcam to control the avatar, we have achieved enhanced non-verbal communication. Initial feedback is very positive. The next step is to conduct extended user studies.},
startyear = {2009},
startmonth = {Sep},
startday = {7},
finishyear = {2009},
finishmonth = {Sep},
finishday = {10},
keyword = {surgery},
keyword = {teamwork},
keyword = {virtual environment},
keyword = {simulation},
conference = {SimTect Healthcare 2009},
day = {10},
}
@inproceedings{marks2009enhancingcommunication3,
author = {Marks, S and Windsor, JA and Wünsche, B},
booktitle = {Proceedings of World Conference on Educational Multimedia, Hypermedia and Telecommunications 2009},
editor = {Siemens, G and Fulford, C},
month = {Jun},
organization = {Honolulu, Hawaii},
pages = {4133--4144},
publisher = {AACE},
title = {Enhancing Virtual-Environment-Based Teamwork Training with Non-Verbal Communication},
url = {http://editlib.org/p/32078/},
year = {2009},
abstract = {Virtual reality simulations for individual training of surgical skills are increasingly used in medical education and have been shown to improve patient outcome. Since recent research suggests that a large percentage of mistakes in clinical settings are due to problems with non-technical skills like communication, teamwork training simulators are developed and used to address this problem. Virtual-environment-based teamwork training simulators are very cost-efficient and allow for non-co-located settings, but have their limitations in communication among the participants. We present an inexpensive camera-based system for capturing aspects of non-verbal communication of participating users and projecting these onto the avatars in the simulation. This additional information has the potential of increasing the realism of the simulation and the effectiveness of team communication, resulting in a better training outcome – for all kinds of simulation that involves human communication.},
startyear = {2009},
startmonth = {Jun},
startday = {22},
finishyear = {2009},
finishmonth = {Jun},
finishday = {26},
isbn = {1-880094-73-8},
keyword = {virtual environment},
keyword = {nonverbal communication},
keyword = {teamwork},
keyword = {training},
conference = {World Conference on Educational Multimedia, Hypermedia and Telecommunications (EDMEDIA) 2009},
day = {26},
}
@inproceedings{marks2009enhancingcommunication2,
author = {Marks, S and Windsor, JA and Wünsche, B},
booktitle = {New Zealand Computer Science Research Student Conference (NZCSRSC) 2009},
month = {Apr},
organization = {Auckland},
title = {Enhancing Virtual Environment-Based Surgical Teamwork Training with Non-Verbal Communication},
url = {http://nzcsrsc09.auckland.ac.nz/programme},
year = {2009},
startyear = {2009},
startmonth = {Apr},
startday = {6},
finishyear = {2009},
finishmonth = {Apr},
finishday = {9},
conference = {New Zealand Computer Science Research Student Conference (NZCSRSC) 2009},
day = {6},
}
@inproceedings{marks2009enhancingcommunication1,
author = {Marks, S and Windsor, JA and Wünsche, B},
booktitle = {GRAPP 2009 - Proceedings of the 4th International Conference on Computer Graphics Theory and Applications},
month = {Feb},
organization = {Lisboa, Portugal},
pages = {361--366},
publisher = {INSTICC Press},
title = {Enhancing Virtual Environment-Based Surgical Teamwork Training With Non-Verbal Communication},
url = {http://hdl.handle.net/10292/3454},
year = {2009},
abstract = {Virtual reality simulations for training surgical skills are increasingly used in medical education and have been shown to improve patient outcome. While advances in hardware and simulation techniques have resulted in many commercial applications for training technical skills, most of these simulators are extremely expensive and do not consider non-technical skills like teamwork and communication. This is a major drawback since recent research suggests that a large percentage of mistakes in clinical settings are due to communication problems. In addition, training teamwork can also improve the efficiency of a surgical team and as such reduce costs and workload.
We present an inexpensive camera-based system for capturing aspects of non-verbal communication of users participating in virtual environment-based teamwork simulations. This data can be used for the enhancement of virtual-environment-based simulations to increase the realism and effectiveness of team communication.},
startyear = {2009},
startmonth = {Feb},
startday = {5},
finishyear = {2009},
finishmonth = {Feb},
finishday = {8},
isbn = {978-989-8111-67-8},
keyword = {virtual environment},
keyword = {nonverbal communication},
keyword = {image processing},
keyword = {training},
conference = {International Conference on Computer Graphics Theory and Applications (GRAPP) 2009},
day = {8},
}
@inproceedings{marks2008cameracommunication,
author = {Marks, S and Windsor, JA and Wünsche, B},
booktitle = {23rd International Conference Image and Vision Computing New Zealand, IVCNZ},
month = {Nov},
organization = {Lincoln, New Zealand},
publisher = {IEEE},
title = {Camera based face tracking for enhancing surgical teamwork training with non-verbal communication},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4762122},
year = {2008},
abstract = {In recent years, the increased use of simulation for the training of surgical skills has improved the medical curriculum and the overall patient outcome.
Advances in hardware and simulation techniques have resulted in many commercial applications for training technical skills. However, most of these simulators are extremely expensive and do not consider non-technical skills like teamwork and communication. This is a major drawback since recent research suggests that a a large percentage of mistakes in clinical settings are due to communication problems. In addition training teamwork can also improve the efficiency of a surgical team and as such reduce costs and workload.
We present an inexpensive camera-based system for the acquisition of aspects of non-verbal communication of users participating in virtual environment-based teamwork simulations. This data can be used for the enhancement of virtual-environment-based simulations to increase the realism and  effectiveness of team communication.},
doi = {10.1109/IVCNZ.2008.4762122},
startyear = {2008},
startmonth = {Nov},
startday = {26},
finishyear = {2008},
finishmonth = {Nov},
finishday = {28},
keyword = {virtual environment},
keyword = {face tracking},
keyword = {nonverbal communication},
conference = {International Conference Image and Vision Computing New Zealand (IVCNZ) 2008},
day = {28},
}
@inproceedings{marks2008evaluationtraining,
author = {Marks, S and Windsor, JA and Wünsche, B},
booktitle = {},
editor = {Holland, J and Nicholas, A and Brignoli, D},
howpublished = {PDF File},
month = {Oct},
organization = {Christchurch, New Zealand},
publisher = {Canterbury University},
title = {Evaluation of Game Engines for Simulated Clinical Training},
url = {http://nzcsrsc08.canterbury.ac.nz/site/proceedings/NZCSRSC_2008_Proceedings.pdf},
year = {2008},
abstract = {The increasing complexity and costs of clinical training and the constant development of new procedures has made virtual reality based training an essential tool in medical education. Unfortunately, commercial training tools are very expensive and have a small support base. Game engines offer unique advantages for the creation of highly interactive and collaborative environments.
This paper examines the suitability of currently available game engines for developing applications for clinical education and training. We formally evaluate a list of available game engines for stability, availability, the possibility of custom content creation and the interaction of multiple users via a network. Based on these criteria, three of the highest ranked engines are used for further case studies.
We found that in general it is possible to easily create scenarios with custom medical models that can be cooperatively viewed and interacted with, though limitations in physical simulation capabilities make some engines less suitable for fully interactive applications. We show that overall game engines represent a good foundation for low cost clinical training applications and we discuss technologies which can be used to further extend their physical simulation capabilities.},
startyear = {2008},
startmonth = {Apr},
startday = {14},
finishyear = {2008},
finishmonth = {Apr},
finishday = {18},
conference = {New Zealand Computer Science Research Student Conference (NZCSRSC) 2008},
day = {1},
}
@inproceedings{marks2007collaborativesimulators,
author = {Marks, S and Windsor, JA and Wünsche, B},
booktitle = {22nd International Conference Image and Vision Computing New Zealand, IVCNZ 2007},
month = {Dec},
organization = {Hamilton, New Zealand},
pages = {205--210},
publisher = {University of Waikato},
title = {Collaborative Soft Object Manipulation for Game Engine-Based Virtual Reality Surgery Simulators},
url = {http://digital.liby.waikato.ac.nz/conferences/ivcnz07/papers/ivcnz07-paper38.pdf},
year = {2007},
abstract = {In this paper we analyse and evaluate the capabilities of popular game engines to simulate and interact with soft objects. We discuss how these engines can be used for simulated surgical training applications, determine their shortcomings and make suggestions how game engines can be extended to make them more suitable for such applications.},
startyear = {2007},
startmonth = {Dec},
startday = {5},
finishyear = {2007},
finishmonth = {Dec},
finishday = {7},
keyword = {game engine},
keyword = {surgical simulation},
keyword = {collaboration},
keyword = {deformation},
conference = {International Conference Image and Vision Computing New Zealand (IVCNZ) 2007},
day = {7},
}
@inproceedings{marks2007evaluationtraining,
author = {Marks, S and Windsor, JA and Wünsche, B},
booktitle = {Proceedings of the 5th International Conference on Computer Graphics and Interactive Techniques in Australia and Southeast Asia},
month = {Dec},
organization = {Perth, Australia},
pages = {273--280},
title = {Evaluation of game engines for simulated surgical training},
url = {http://portal.acm.org/citation.cfm?id=1321311},
year = {2007},
abstract = {The increasing complexity and costs of surgical training and the constant development of new surgical procedures has made virtual surgical training an essential tool in medical education. Unfortunately, commercial tools are very expensive and have a small support base. Game engines offer unique advantages for the creation of highly interactive and collaborative environments.

This paper examines the suitability of currently available game engines for developing applications for medical education and simulated surgical training. We formally evaluate a list of available game engines for stability, availability, the possibility of custom content creation and the interaction of multiple users via a network. Based on these criteria, three of the highest ranked engines are used for further case studies.

We found that in general it is possible to easily create scenarios with custom medical models that can be cooperatively viewed and interacted with. Limitations in physical simulation capabilities make some engines unsuitable for fully interactive applications, but they can be used in combination with predefined animations. We show that overall game engines represent a good foundation for low cost virtual surgery applications and we discuss technologies which can be used to further extend their physical simulation capabilities.},
doi = {10.1145/1321261.1321311},
isbn = {978-1-59593-912-8},
conference = {GRAPHITE '07 Proceedings of the 5th international conference on Computer graphics and interactive techniques in Australia and Southeast Asia},
day = {4},
}
@misc{marks2007dontthem,
author = {Marks, S},
month = {Oct},
note = {This poster won the 1st prize at the University of Auckland 2007 Exposure poster competition},
title = {Don't Shoot Them - Heal Them},
url = {http://www.auckland.ac.nz/uoa/exposure-past-winners#s2c5},
year = {2007},
abstract = {Virtual surgery training has become an essential tool in medical education. Unfortunately, commercial simulators are very expensive and mainly focus on individual training instead of teamwork. Game engines offer unique advantages for the inexpensive creation of interactive and collaborative environments. We show that it is possible to easily design multi-user scenarios with custom medical models. Our results will help to develop low cost surgical simulators that will improve health care outcomes for smaller hospitals or in regions which do not have access to advanced training tools.},
keyword = {game engine},
keyword = {surgical simulation},
keyword = {teamwork},
conference = {Exposure 2007},
day = {10},
}
@article{henriques2007anapplications,
author = {Henriques, A and Wünsche, B and Marks, S},
journal = {Computer-Assisted Radiology and Surgery},
pages = {S169--S171},
title = {An investigation of meshless deformation for fast soft tissue simulation in virtual surgery applications},
url = {http://www.springerlink.com/content/f927j24624473443/},
volume = {2},
year = {2007},
doi = {10.1007/s11548-007-0091-7},
issn = {1861-6410},
eissn = {1861-6429},
issue = {1 SUPPL.},
keyword = {mesh},
keyword = {deformation},
keyword = {meshless},
}
@inproceedings{marks2006evolvingstrategies2,
author = {Marks, S and Conen, W and Lux, G},
booktitle = {Proceedings of the ninth 3IA International Conference on Computer Graphics and Artificial Intelligence 3iA2006},
month = {May},
organization = {Limoges, Paris},
pages = {183--190},
title = {Evolving autonomous locomotion of virtual characters in simulated physical environment via neural networks and evolutionary strategies},
url = {http://3ia.teiath.gr/3ia_previous_conferences_cds/2006/Papers/ShortPaper01.html},
year = {2006},
abstract = {In this paper we examine principles to automatise or to support the process of animation of an articulated character by allowing it to “learn” its movements autonomously. For this, it is necessary to model the physical properties of the character, connect virtual sensors and actuators to a neural network, and adjust the weights and thresholds of the network with evolutionary strategies. We conclude with a discussion and showcase of the results and present ways for further improvement.},
startyear = {2006},
startmonth = {May},
startday = {23},
finishyear = {2006},
finishmonth = {May},
finishday = {24},
keyword = {virtual reality},
keyword = {animation},
keyword = {computer graphics},
keyword = {physical simulation},
keyword = {neural networks},
conference = {3iA2006},
day = {24},
}
@mastersthesis{marks2006evolvingstrategies1,
author = {Marks, S},
editor = {Lux, G and Conen, W},
month = {Jan},
organization = {Gelsenkirchen, Germany},
title = {Evolving autonomous locomotion of virtual characters in a simulated physical environment via neural networks and evolutionary strategies},
year = {2006},
abstract = {The animation of virtual characters is a process that although supported by various software and hardware can be tedious and costly especially when the character to animate is very complicated and/or detailed. The method presented in this thesis tries to automatize or to support this process by letting the character 'learn' its movements autonomously. 
This is established by first modelling physical properties (e.g. mass, inertia moments, joints, degrees of freedom) additionally to the optical ones to allow the interaction of the character with a simulated physical environment. In the second step the sensors (e.g. pressure, forces, angles, speed) and actors (e.g. motors, 'muscles', suspension elements) that the character uses are defined. Third the sensors and actors are connected with the inputs and outputs of a neural network whose bias values and link weights are still uninitialized. These values are then modified by evolutionary strategies to find naturally looking movements of the character in its physical environment.},
confidential = {False},
conference = {University of Applied Sciences Gelsenkirchen},
day = {10},
}
